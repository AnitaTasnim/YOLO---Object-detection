{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11616887,"sourceType":"datasetVersion","datasetId":7287412},{"sourceId":11620802,"sourceType":"datasetVersion","datasetId":7290107}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Install required packages\n!pip install -q scikit-learn\n\n \n","metadata":{"id":"CEzdnJOAZngD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2dc70bbc-6e6e-4b11-93d8-b4571ded623b","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:52:11.330609Z","iopub.execute_input":"2025-05-06T12:52:11.330810Z","iopub.status.idle":"2025-05-06T12:52:15.446103Z","shell.execute_reply.started":"2025-05-06T12:52:11.330792Z","shell.execute_reply":"2025-05-06T12:52:15.445050Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"with open('/kaggle/input/d/anitatasnimproma/tinycoco1/labels/train2017/000000000009.txt') as f:\n    print(f.read())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K39ZkFzF24Kc","outputId":"df9d0ebd-83c6-4915-cb91-4613dcfe0eab","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:52:15.448570Z","iopub.execute_input":"2025-05-06T12:52:15.448872Z","iopub.status.idle":"2025-05-06T12:52:15.467279Z","shell.execute_reply.started":"2025-05-06T12:52:15.448846Z","shell.execute_reply":"2025-05-06T12:52:15.466584Z"}},"outputs":[{"name":"stdout","text":"45 0.479492 0.688771 0.955609 0.5955\n45 0.736516 0.247188 0.498875 0.476417\n50 0.637063 0.732938 0.494125 0.510583\n45 0.339438 0.418896 0.678875 0.7815\n49 0.646836 0.132552 0.118047 0.0969375\n49 0.773148 0.129802 0.0907344 0.0972292\n49 0.668297 0.226906 0.131281 0.146896\n49 0.642859 0.0792187 0.148063 0.148062\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimg_path = '/kaggle/input/d/anitatasnimproma/tinycoco1/images/train2017/000000000009.jpg'\nprint(\"Exists?\" , os.path.exists(img_path))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzT3IsFS24M1","outputId":"c72b6dac-31d6-4b1f-d873-43fbb7844b6f","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:52:15.468005Z","iopub.execute_input":"2025-05-06T12:52:15.468264Z","iopub.status.idle":"2025-05-06T12:52:15.480297Z","shell.execute_reply.started":"2025-05-06T12:52:15.468238Z","shell.execute_reply":"2025-05-06T12:52:15.479558Z"}},"outputs":[{"name":"stdout","text":"Exists? True\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ─── 1) Install PyTorch 1.13.1 + CUDA 11.7 and other deps ───────────────────\n!pip uninstall -y torch torchvision torchaudio\n!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 \\\n    --extra-index-url https://download.pytorch.org/whl/cu117\n!pip install opencv-python==4.5.5.64 PyYAML tqdm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"190389ba-ccd5-410e-b1d7-c44f83294b54","id":"cZxCc7y-Wb2N","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:52:15.481142Z","iopub.execute_input":"2025-05-06T12:52:15.481378Z","iopub.status.idle":"2025-05-06T12:53:18.011295Z","shell.execute_reply.started":"2025-05-06T12:52:15.481356Z","shell.execute_reply":"2025-05-06T12:53:18.010483Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.5.1+cu124\nUninstalling torch-2.5.1+cu124:\n  Successfully uninstalled torch-2.5.1+cu124\nFound existing installation: torchvision 0.20.1+cu124\nUninstalling torchvision-0.20.1+cu124:\n  Successfully uninstalled torchvision-0.20.1+cu124\nFound existing installation: torchaudio 2.5.1+cu124\nUninstalling torchaudio-2.5.1+cu124:\n  Successfully uninstalled torchaudio-2.5.1+cu124\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\nCollecting torch==1.13.1+cu117\n  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp311-cp311-linux_x86_64.whl (1801.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m518.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1+cu117 (from versions: 0.1.6, 0.2.0, 0.15.0+cu117, 0.15.1, 0.15.1+cu117, 0.15.2, 0.15.2+cu117, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1+cu117\u001b[0m\u001b[31m\n\u001b[0mCollecting opencv-python==4.5.5.64\n  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.5.5.64) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python==4.5.5.64) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (2024.2.0)\nDownloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: opencv-python\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.11.0.86\n    Uninstalling opencv-python-4.11.0.86:\n      Successfully uninstalled opencv-python-4.11.0.86\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed opencv-python-4.5.5.64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ─── 1) Install PyTorch 1.13.1 + CUDA 11.7 and other deps ───────────────────\n!pip uninstall -y torch torchvision torchaudio\n!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 \\\n    --extra-index-url https://download.pytorch.org/whl/cu117\n!pip install opencv-python==4.5.5.64 PyYAML tqdm\n","metadata":{"id":"TacLG-33Z3BZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2135183-4098-4450-f4c0-5399a58a8111","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:53:18.012488Z","iopub.execute_input":"2025-05-06T12:53:18.012803Z","iopub.status.idle":"2025-05-06T12:53:42.259938Z","shell.execute_reply.started":"2025-05-06T12:53:18.012776Z","shell.execute_reply":"2025-05-06T12:53:42.259012Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\nCollecting torch==1.13.1+cu117\n  Using cached https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp311-cp311-linux_x86_64.whl (1801.8 MB)\n\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1+cu117 (from versions: 0.1.6, 0.2.0, 0.15.0+cu117, 0.15.1, 0.15.1+cu117, 0.15.2, 0.15.2+cu117, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1+cu117\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: opencv-python==4.5.5.64 in /usr/local/lib/python3.11/dist-packages (4.5.5.64)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.5.5.64) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python==4.5.5.64) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python==4.5.5.64) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python==4.5.5.64) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install torch","metadata":{"id":"QC3v5W8We8Cl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95b22bab-dbb6-4543-b095-4438b64b59c1","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:53:42.261102Z","iopub.execute_input":"2025-05-06T12:53:42.261413Z","iopub.status.idle":"2025-05-06T12:56:17.296325Z","shell.execute_reply.started":"2025-05-06T12:53:42.261384Z","shell.execute_reply":"2025-05-06T12:56:17.295603Z"}},"outputs":[{"name":"stdout","text":"Collecting torch\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nCollecting sympy>=1.13.3 (from torch)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.0 (from torch)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nfastai 2.7.18 requires torchvision>=0.11, which is not installed.\ntimm 1.0.14 requires torchvision, which is not installed.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.7.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install -U numpy","metadata":{"id":"zXrSslEdgxqW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"498abf1d-a5f4-401a-abd0-cc086ece91ba","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:17.298862Z","iopub.execute_input":"2025-05-06T12:56:17.299112Z","iopub.status.idle":"2025-05-06T12:56:25.467297Z","shell.execute_reply.started":"2025-05-06T12:56:17.299089Z","shell.execute_reply":"2025-05-06T12:56:25.466569Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nCollecting numpy\n  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nfastai 2.7.18 requires torchvision>=0.11, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.5 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.5 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.5 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.5 which is incompatible.\ncatboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.2.5 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\nmatplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 2.2.5 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nthinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.5 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.5 which is incompatible.\nibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nlangchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.2.5 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.7.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-2.2.5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Upgrade to the newest opencv-python wheel (built against NumPy 2.x)\n!pip install --upgrade opencv-python\n","metadata":{"id":"ehQYwA7HhZpY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef6ce6b5-23ce-4eac-8552-ed4f6aaa20bc","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:25.468178Z","iopub.execute_input":"2025-05-06T12:56:25.468386Z","iopub.status.idle":"2025-05-06T12:56:30.862875Z","shell.execute_reply.started":"2025-05-06T12:56:25.468366Z","shell.execute_reply":"2025-05-06T12:56:30.862031Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.5.5.64)\nCollecting opencv-python\n  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.2.5)\nDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: opencv-python\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.5.5.64\n    Uninstalling opencv-python-4.5.5.64:\n      Successfully uninstalled opencv-python-4.5.5.64\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed opencv-python-4.11.0.86\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# utils","metadata":{"id":"HZ8Ny3sxPCfv"}},{"cell_type":"code","source":"import os\n\n# Create the directory if it doesn't exist\nos.makedirs(\"utils\", exist_ok=True)\n","metadata":{"id":"gbtFb1qUqSqJ","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.863817Z","iopub.execute_input":"2025-05-06T12:56:30.864016Z","iopub.status.idle":"2025-05-06T12:56:30.868246Z","shell.execute_reply.started":"2025-05-06T12:56:30.863997Z","shell.execute_reply":"2025-05-06T12:56:30.867515Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## args","metadata":{"id":"940qoVLm42AX"}},{"cell_type":"code","source":"%%writefile utils/args.yaml\nlr0: 0.010                    # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.010                    # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.93700000          # SGD momentum/Adam beta1\nweight_decay: 0.0005          # optimizer weight decay 5e-4\nwarmup_epochs: 3.000          # warmup epochs\nwarmup_momentum: 0.8          # warmup initial momentum\nwarmup_bias_lr: 0.10          # warmup initial bias lr\nbox: 7.5                      # box loss gain\ncls: 0.5                      # cls loss gain\ndfl: 1.5                      # cls loss gain\nhsv_h: 0.015000               # image HSV-Hue augmentation (fraction)\nhsv_s: 0.700000               # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.400000               # image HSV-Value augmentation (fraction)\ndegrees: 0.0000               # image rotation (+/- deg)\ntranslate: 0.10               # image translation (+/- fraction)\nscale: 0.500000               # image scale (+/- gain)\nshear: 0.000000               # image shear (+/- deg)\nflip_ud: 0.0000               # image flip up-down (probability)\nflip_lr: 0.5000               # image flip left-right (probability)\nmosaic: 1.00000               # image mosaic (probability)\nmix_up: 0.00000               # image mix-up (probability)\n# classes\nnames:\n  0: person\n  1: bicycle\n  2: car\n  3: motorcycle\n  4: airplane\n  5: bus\n  6: train\n  7: truck\n  8: boat\n  9: traffic light\n  10: fire hydrant\n  11: stop sign\n  12: parking meter\n  13: bench\n  14: bird\n  15: cat\n  16: dog\n  17: horse\n  18: sheep\n  19: cow\n  20: elephant\n  21: bear\n  22: zebra\n  23: giraffe\n  24: backpack\n  25: umbrella\n  26: handbag\n  27: tie\n  28: suitcase\n  29: frisbee\n  30: skis\n  31: snowboard\n  32: sports ball\n  33: kite\n  34: baseball bat\n  35: baseball glove\n  36: skateboard\n  37: surfboard\n  38: tennis racket\n  39: bottle\n  40: wine glass\n  41: cup\n  42: fork\n  43: knife\n  44: spoon\n  45: bowl\n  46: banana\n  47: apple\n  48: sandwich\n  49: orange\n  50: broccoli\n  51: carrot\n  52: hot dog\n  53: pizza\n  54: donut\n  55: cake\n  56: chair\n  57: couch\n  58: potted plant\n  59: bed\n  60: dining table\n  61: toilet\n  62: tv\n  63: laptop\n  64: mouse\n  65: remote\n  66: keyboard\n  67: cell phone\n  68: microwave\n  69: oven\n  70: toaster\n  71: sink\n  72: refrigerator\n  73: book\n  74: clock\n  75: vase\n  76: scissors\n  77: teddy bear\n  78: hair drier\n  79: toothbrush\n\n","metadata":{"id":"0-2hDyhK3OGa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b0aa2ca-1d86-46b4-d282-106355c090e5","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.869108Z","iopub.execute_input":"2025-05-06T12:56:30.869737Z","iopub.status.idle":"2025-05-06T12:56:30.886162Z","shell.execute_reply.started":"2025-05-06T12:56:30.869715Z","shell.execute_reply":"2025-05-06T12:56:30.885461Z"}},"outputs":[{"name":"stdout","text":"Writing utils/args.yaml\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## dataset","metadata":{"id":"9F85CnjT45Rw"}},{"cell_type":"code","source":"%%writefile utils/dataset.py\nimport os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom torch.serialization import add_safe_globals\n\nimport math\nimport os\nimport random\n\nimport cv2\nimport numpy\nimport torch\nfrom PIL import Image\nfrom torch.utils import data\n\nFORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp'\n\n\nclass Dataset(data.Dataset):\n    def __init__(self, filenames, input_size, params, augment):\n        self.params = params\n        self.mosaic = augment\n        self.augment = augment\n        self.input_size = input_size\n\n        # Read labels\n        cache = self.load_label(filenames)\n        labels, shapes = zip(*cache.values())\n        self.labels = list(labels)\n        self.shapes = numpy.array(shapes, dtype=numpy.float64)\n        self.filenames = list(cache.keys())  # update\n        self.n = len(shapes)  # number of samples\n        self.indices = range(self.n)\n        # Albumentations (optional, only used if package is installed)\n        self.albumentations = Albumentations()\n\n    def __getitem__(self, index):\n        index = self.indices[index]\n\n        params = self.params\n        mosaic = self.mosaic and random.random() < params['mosaic']\n\n        if mosaic:\n            shapes = None\n            # Load MOSAIC\n            image, label = self.load_mosaic(index, params)\n            # MixUp augmentation\n            if random.random() < params['mix_up']:\n                index = random.choice(self.indices)\n                mix_image1, mix_label1 = image, label\n                mix_image2, mix_label2 = self.load_mosaic(index, params)\n\n                image, label = mix_up(mix_image1, mix_label1, mix_image2, mix_label2)\n        else:\n            # Load image\n            image, shape = self.load_image(index)\n            h, w = image.shape[:2]\n\n            # Resize\n            image, ratio, pad = resize(image, self.input_size, self.augment)\n            shapes = shape, ((h / shape[0], w / shape[1]), pad)  # for COCO mAP rescaling\n\n            label = self.labels[index].copy()\n            if label.size:\n                label[:, 1:] = wh2xy(label[:, 1:], ratio[0] * w, ratio[1] * h, pad[0], pad[1])\n            if self.augment:\n                image, label = random_perspective(image, label, params)\n        nl = len(label)  # number of labels\n        if nl:\n            label[:, 1:5] = xy2wh(label[:, 1:5], image.shape[1], image.shape[0])\n\n        if self.augment:\n            # Albumentations\n            image, label = self.albumentations(image, label)\n            nl = len(label)  # update after albumentations\n            # HSV color-space\n            augment_hsv(image, params)\n            # Flip up-down\n            if random.random() < params['flip_ud']:\n                image = numpy.flipud(image)\n                if nl:\n                    label[:, 2] = 1 - label[:, 2]\n            # Flip left-right\n            if random.random() < params['flip_lr']:\n                image = numpy.fliplr(image)\n                if nl:\n                    label[:, 1] = 1 - label[:, 1]\n\n        target = torch.zeros((nl, 6))\n        if nl:\n            target[:, 1:] = torch.from_numpy(label)\n\n        # Convert HWC to CHW, BGR to RGB\n        sample = image.transpose((2, 0, 1))[::-1]\n        sample = numpy.ascontiguousarray(sample)\n\n        return torch.from_numpy(sample), target, shapes\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def load_image(self, i):\n        image = cv2.imread(self.filenames[i])\n        h, w = image.shape[:2]\n        r = self.input_size / max(h, w)\n        if r != 1:\n            image = cv2.resize(image,\n                               dsize=(int(w * r), int(h * r)),\n                               interpolation=resample() if self.augment else cv2.INTER_LINEAR)\n        return image, (h, w)\n\n    def load_mosaic(self, index, params):\n        label4 = []\n        image4 = numpy.full((self.input_size * 2, self.input_size * 2, 3), 0, dtype=numpy.uint8)\n        y1a, y2a, x1a, x2a, y1b, y2b, x1b, x2b = (None, None, None, None, None, None, None, None)\n\n        border = [-self.input_size // 2, -self.input_size // 2]\n\n        xc = int(random.uniform(-border[0], 2 * self.input_size + border[1]))\n        yc = int(random.uniform(-border[0], 2 * self.input_size + border[1]))\n\n        indices = [index] + random.choices(self.indices, k=3)\n        random.shuffle(indices)\n\n        for i, index in enumerate(indices):\n            # Load image\n            image, _ = self.load_image(index)\n            shape = image.shape\n            if i == 0:  # top left\n                x1a = max(xc - shape[1], 0)\n                y1a = max(yc - shape[0], 0)\n                x2a = xc\n                y2a = yc\n                x1b = shape[1] - (x2a - x1a)\n                y1b = shape[0] - (y2a - y1a)\n                x2b = shape[1]\n                y2b = shape[0]\n            if i == 1:  # top right\n                x1a = xc\n                y1a = max(yc - shape[0], 0)\n                x2a = min(xc + shape[1], self.input_size * 2)\n                y2a = yc\n                x1b = 0\n                y1b = shape[0] - (y2a - y1a)\n                x2b = min(shape[1], x2a - x1a)\n                y2b = shape[0]\n            if i == 2:  # bottom left\n                x1a = max(xc - shape[1], 0)\n                y1a = yc\n                x2a = xc\n                y2a = min(self.input_size * 2, yc + shape[0])\n                x1b = shape[1] - (x2a - x1a)\n                y1b = 0\n                x2b = shape[1]\n                y2b = min(y2a - y1a, shape[0])\n            if i == 3:  # bottom right\n                x1a = xc\n                y1a = yc\n                x2a = min(xc + shape[1], self.input_size * 2)\n                y2a = min(self.input_size * 2, yc + shape[0])\n                x1b = 0\n                y1b = 0\n                x2b = min(shape[1], x2a - x1a)\n                y2b = min(y2a - y1a, shape[0])\n\n            image4[y1a:y2a, x1a:x2a] = image[y1b:y2b, x1b:x2b]\n            pad_w = x1a - x1b\n            pad_h = y1a - y1b\n\n            # Labels\n            label = self.labels[index].copy()\n            if len(label):\n                label[:, 1:] = wh2xy(label[:, 1:], shape[1], shape[0], pad_w, pad_h)\n            label4.append(label)\n\n        # Concat/clip labels\n        label4 = numpy.concatenate(label4, 0)\n        for x in label4[:, 1:]:\n            numpy.clip(x, 0, 2 * self.input_size, out=x)\n\n        # Augment\n        image4, label4 = random_perspective(image4, label4, params, border)\n\n        return image4, label4\n\n    @staticmethod\n    def collate_fn(batch):\n        samples, targets, shapes = zip(*batch)\n        for i, item in enumerate(targets):\n            item[:, 0] = i  # add target image index\n        return torch.stack(samples, 0), torch.cat(targets, 0), shapes\n\n    \n    \n    \n    @staticmethod\n\n\n      \n    def load_label(filenames):\n        cache_path = '/kaggle/working/dataset.cache'\n        \n        # Allow numpy unpickling\n        add_safe_globals([np.core.multiarray._reconstruct])\n    \n        if os.path.exists(cache_path):\n            return torch.load(cache_path, weights_only=False)\n    \n        x = {}\n        for filename in filenames:\n            try:\n                # verify image\n                with open(filename, 'rb') as f:\n                    image = Image.open(f)\n                    image.verify()\n                shape = image.size\n                assert shape[0] > 9 and shape[1] > 9, f'image size {shape} <10 pixels'\n                assert image.format.lower() in FORMATS, f'invalid image format {image.format}'\n    \n                # match image path to label path\n                a = f'{os.sep}images{os.sep}'\n                b = f'{os.sep}labels{os.sep}'\n                label_path = b.join(filename.rsplit(a, 1)).rsplit('.', 1)[0] + '.txt'\n    \n                if os.path.isfile(label_path):\n                    with open(label_path) as f:\n                        label = [x.split() for x in f.read().strip().splitlines() if len(x)]\n                        label = np.array(label, dtype=np.float32)\n                    nl = len(label)\n                    if nl:\n                        assert label.shape[1] == 5, 'labels require 5 columns'\n                        assert (label >= 0).all(), 'negative label values'\n                        assert (label[:, 1:] <= 1).all(), 'non-normalized coordinates'\n                        _, i = np.unique(label, axis=0, return_index=True)\n                        if len(i) < nl:\n                            label = label[i]\n                    else:\n                        label = np.zeros((0, 5), dtype=np.float32)\n                else:\n                    label = np.zeros((0, 5), dtype=np.float32)\n    \n                x[filename] = [label, shape]\n            except FileNotFoundError:\n                pass\n    \n        torch.save(x, cache_path)\n        return x\n\n    \n\ndef wh2xy(x, w=640, h=640, pad_w=0, pad_h=0):\n    # Convert nx4 boxes\n    # from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    y = numpy.copy(x)\n    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + pad_w  # top left x\n    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + pad_h  # top left y\n    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + pad_w  # bottom right x\n    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + pad_h  # bottom right y\n    return y\n\n\ndef xy2wh(x, w=640, h=640):\n    # warning: inplace clip\n    x[:, [0, 2]] = x[:, [0, 2]].clip(0, w - 1E-3)  # x1, x2\n    x[:, [1, 3]] = x[:, [1, 3]].clip(0, h - 1E-3)  # y1, y2\n\n    # Convert nx4 boxes\n    # from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right\n    y = numpy.copy(x)\n    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # x center\n    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # y center\n    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # width\n    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # height\n    return y\n\n\ndef resample():\n    choices = (cv2.INTER_AREA,\n               cv2.INTER_CUBIC,\n               cv2.INTER_LINEAR,\n               cv2.INTER_NEAREST,\n               cv2.INTER_LANCZOS4)\n    return random.choice(seq=choices)\n\n\ndef augment_hsv(image, params):\n    # HSV color-space augmentation\n    h = params['hsv_h']\n    s = params['hsv_s']\n    v = params['hsv_v']\n\n    r = numpy.random.uniform(-1, 1, 3) * [h, s, v] + 1\n    h, s, v = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n\n    x = numpy.arange(0, 256, dtype=r.dtype)\n    lut_h = ((x * r[0]) % 180).astype('uint8')\n    lut_s = numpy.clip(x * r[1], 0, 255).astype('uint8')\n    lut_v = numpy.clip(x * r[2], 0, 255).astype('uint8')\n\n    im_hsv = cv2.merge((cv2.LUT(h, lut_h), cv2.LUT(s, lut_s), cv2.LUT(v, lut_v)))\n    cv2.cvtColor(im_hsv, cv2.COLOR_HSV2BGR, dst=image)  # no return needed\n\n\ndef resize(image, input_size, augment):\n    # Resize and pad image while meeting stride-multiple constraints\n    shape = image.shape[:2]  # current shape [height, width]\n\n    # Scale ratio (new / old)\n    r = min(input_size / shape[0], input_size / shape[1])\n    if not augment:  # only scale down, do not scale up (for better val mAP)\n        r = min(r, 1.0)\n\n    # Compute padding\n    pad = int(round(shape[1] * r)), int(round(shape[0] * r))\n    w = (input_size - pad[0]) / 2\n    h = (input_size - pad[1]) / 2\n\n    if shape[::-1] != pad:  # resize\n        image = cv2.resize(image,\n                           dsize=pad,\n                           interpolation=resample() if augment else cv2.INTER_LINEAR)\n    top, bottom = int(round(h - 0.1)), int(round(h + 0.1))\n    left, right = int(round(w - 0.1)), int(round(w + 0.1))\n    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)  # add border\n    return image, (r, r), (w, h)\n\n\ndef candidates(box1, box2):\n    # box1(4,n), box2(4,n)\n    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]\n    aspect_ratio = numpy.maximum(w2 / (h2 + 1e-16), h2 / (w2 + 1e-16))  # aspect ratio\n    return (w2 > 2) & (h2 > 2) & (w2 * h2 / (w1 * h1 + 1e-16) > 0.1) & (aspect_ratio < 100)\n\n\ndef random_perspective(samples, targets, params, border=(0, 0)):\n    h = samples.shape[0] + border[0] * 2\n    w = samples.shape[1] + border[1] * 2\n\n    # Center\n    center = numpy.eye(3)\n    center[0, 2] = -samples.shape[1] / 2  # x translation (pixels)\n    center[1, 2] = -samples.shape[0] / 2  # y translation (pixels)\n\n    # Perspective\n    perspective = numpy.eye(3)\n\n    # Rotation and Scale\n    rotate = numpy.eye(3)\n    a = random.uniform(-params['degrees'], params['degrees'])\n    s = random.uniform(1 - params['scale'], 1 + params['scale'])\n    rotate[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)\n\n    # Shear\n    shear = numpy.eye(3)\n    shear[0, 1] = math.tan(random.uniform(-params['shear'], params['shear']) * math.pi / 180)\n    shear[1, 0] = math.tan(random.uniform(-params['shear'], params['shear']) * math.pi / 180)\n\n    # Translation\n    translate = numpy.eye(3)\n    translate[0, 2] = random.uniform(0.5 - params['translate'], 0.5 + params['translate']) * w\n    translate[1, 2] = random.uniform(0.5 - params['translate'], 0.5 + params['translate']) * h\n\n    # Combined rotation matrix, order of operations (right to left) is IMPORTANT\n    matrix = translate @ shear @ rotate @ perspective @ center\n    if (border[0] != 0) or (border[1] != 0) or (matrix != numpy.eye(3)).any():  # image changed\n        samples = cv2.warpAffine(samples, matrix[:2], dsize=(w, h), borderValue=(0, 0, 0))\n\n    # Transform label coordinates\n    n = len(targets)\n    if n:\n        xy = numpy.ones((n * 4, 3))\n        xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\n        xy = xy @ matrix.T  # transform\n        xy = xy[:, :2].reshape(n, 8)  # perspective rescale or affine\n\n        # create new boxes\n        x = xy[:, [0, 2, 4, 6]]\n        y = xy[:, [1, 3, 5, 7]]\n        new = numpy.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n\n        # clip\n        new[:, [0, 2]] = new[:, [0, 2]].clip(0, w)\n        new[:, [1, 3]] = new[:, [1, 3]].clip(0, h)\n\n        # filter candidates\n        indices = candidates(box1=targets[:, 1:5].T * s, box2=new.T)\n        targets = targets[indices]\n        targets[:, 1:5] = new[indices]\n\n    return samples, targets\n\n\ndef mix_up(image1, label1, image2, label2):\n    # Applies MixUp augmentation https://arxiv.org/pdf/1710.09412.pdf\n    alpha = numpy.random.beta(32.0, 32.0)  # mix-up ratio, alpha=beta=32.0\n    image = (image1 * alpha + image2 * (1 - alpha)).astype(numpy.uint8)\n    label = numpy.concatenate((label1, label2), 0)\n    return image, label\n\n\nclass Albumentations:\n    def __init__(self):\n        self.transform = None\n        try:\n            import albumentations as album\n\n            transforms = [album.Blur(p=0.01),\n                          album.CLAHE(p=0.01),\n                          album.ToGray(p=0.01),\n                          album.MedianBlur(p=0.01)]\n            self.transform = album.Compose(transforms,\n                                           album.BboxParams('yolo', ['class_labels']))\n\n        except ImportError:  # package not installed, skip\n            pass\n\n    def __call__(self, image, label):\n        if self.transform:\n            x = self.transform(image=image,\n                               bboxes=label[:, 1:],\n                               class_labels=label[:, 0])\n            image = x['image']\n            label = numpy.array([[c, *b] for c, b in zip(x['class_labels'], x['bboxes'])])\n        return image, label","metadata":{"id":"O7Jo-w4HIuHf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"606d346b-4995-4749-f3a5-450f3057a151","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.887197Z","iopub.execute_input":"2025-05-06T12:56:30.887431Z","iopub.status.idle":"2025-05-06T12:56:30.907079Z","shell.execute_reply.started":"2025-05-06T12:56:30.887414Z","shell.execute_reply":"2025-05-06T12:56:30.906427Z"}},"outputs":[{"name":"stdout","text":"Writing utils/dataset.py\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# New Section","metadata":{"id":"iIFZ-iadQYt4"}},{"cell_type":"markdown","source":"## util","metadata":{"id":"tWbLRgbarSLx"}},{"cell_type":"code","source":"%%writefile utils/util.py\n\n\n\nimport copy\nimport math\nimport random\nimport time\n\nimport numpy\nimport torch\nimport torchvision\nfrom torch.nn.functional import cross_entropy, one_hot\n\n\ndef setup_seed():\n    \"\"\"\n    Setup random seed.\n    \"\"\"\n    random.seed(0)\n    numpy.random.seed(0)\n    torch.manual_seed(0)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n\ndef setup_multi_processes():\n    \"\"\"\n    Setup multi-processing environment variables.\n    \"\"\"\n    import cv2\n    from os import environ\n    from platform import system\n\n    # set multiprocess start method as `fork` to speed up the training\n    if system() != 'Windows':\n        torch.multiprocessing.set_start_method('fork', force=True)\n\n    # disable opencv multithreading to avoid system being overloaded\n    cv2.setNumThreads(0)\n\n    # setup OMP threads\n    if 'OMP_NUM_THREADS' not in environ:\n        environ['OMP_NUM_THREADS'] = '1'\n\n    # setup MKL threads\n    if 'MKL_NUM_THREADS' not in environ:\n        environ['MKL_NUM_THREADS'] = '1'\n\n\ndef scale(coords, shape1, shape2, ratio_pad=None):\n    if ratio_pad is None:  # calculate from img0_shape\n        gain = min(shape1[0] / shape2[0], shape1[1] / shape2[1])  # gain  = old / new\n        pad = (shape1[1] - shape2[1] * gain) / 2, (shape1[0] - shape2[0] * gain) / 2  # wh padding\n    else:\n        gain = ratio_pad[0][0]\n        pad = ratio_pad[1]\n\n    coords[:, [0, 2]] -= pad[0]  # x padding\n    coords[:, [1, 3]] -= pad[1]  # y padding\n    coords[:, :4] /= gain\n\n    coords[:, 0].clamp_(0, shape2[1])  # x1\n    coords[:, 1].clamp_(0, shape2[0])  # y1\n    coords[:, 2].clamp_(0, shape2[1])  # x2\n    coords[:, 3].clamp_(0, shape2[0])  # y2\n    return coords\n\n\ndef make_anchors(x, strides, offset=0.5):\n    \"\"\"\n    Generate anchors from features\n    \"\"\"\n    assert x is not None\n    anchor_points, stride_tensor = [], []\n    for i, stride in enumerate(strides):\n        _, _, h, w = x[i].shape\n        sx = torch.arange(end=w, dtype=x[i].dtype, device=x[i].device) + offset  # shift x\n        sy = torch.arange(end=h, dtype=x[i].dtype, device=x[i].device) + offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx)\n        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))\n        stride_tensor.append(torch.full((h * w, 1), stride, dtype=x[i].dtype, device=x[i].device))\n    return torch.cat(anchor_points), torch.cat(stride_tensor)\n\n\ndef box_iou(box1, box2):\n    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n    \"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        box1 (Tensor[N, 4])\n        box2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise\n            IoU values for every element in boxes1 and boxes2\n    \"\"\"\n\n    # intersection(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)\n    (a1, a2), (b1, b2) = box1[:, None].chunk(2, 2), box2.chunk(2, 1)\n    intersection = (torch.min(a2, b2) - torch.max(a1, b1)).clamp(0).prod(2)\n\n    # IoU = intersection / (area1 + area2 - intersection)\n    box1 = box1.T\n    box2 = box2.T\n\n    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n\n    return intersection / (area1[:, None] + area2 - intersection)\n\n\ndef wh2xy(x):\n    y = x.clone()\n    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x\n    y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y\n    y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x\n    y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y\n    return y\n\n\ndef non_max_suppression(prediction, conf_threshold=0.25, iou_threshold=0.45):\n    nc = prediction.shape[1] - 4  # number of classes\n    xc = prediction[:, 4:4 + nc].amax(1) > conf_threshold  # candidates\n\n    # Settings\n    max_wh = 7680  # (pixels) maximum box width and height\n    max_det = 300  # the maximum number of boxes to keep after NMS\n    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n\n    start = time.time()\n    outputs = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n    for index, x in enumerate(prediction):  # image index, image inference\n        # Apply constraints\n        x = x.transpose(0, -1)[xc[index]]  # confidence\n\n        # If none remain process next image\n        if not x.shape[0]:\n            continue\n\n        # Detections matrix nx6 (box, conf, cls)\n        box, cls = x.split((4, nc), 1)\n        # center_x, center_y, width, height) to (x1, y1, x2, y2)\n        box = wh2xy(box)\n        if nc > 1:\n            i, j = (cls > conf_threshold).nonzero(as_tuple=False).T\n            x = torch.cat((box[i], x[i, 4 + j, None], j[:, None].float()), 1)\n        else:  # best class only\n            conf, j = cls.max(1, keepdim=True)\n            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_threshold]\n        # Check shape\n        if not x.shape[0]:  # no boxes\n            continue\n        # sort by confidence and remove excess boxes\n        x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n\n        # Batched NMS\n        c = x[:, 5:6] * max_wh  # classes\n        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n        i = torchvision.ops.nms(boxes, scores, iou_threshold)  # NMS\n        i = i[:max_det]  # limit detections\n        outputs[index] = x[i]\n        if (time.time() - start) > 0.5 + 0.05 * prediction.shape[0]:\n            print(f'WARNING ⚠️ NMS time limit {0.5 + 0.05 * prediction.shape[0]:.3f}s exceeded')\n            break  # time limit exceeded\n\n    return outputs\n\n\ndef smooth(y, f=0.05):\n    # Box filter of fraction f\n    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)\n    p = numpy.ones(nf // 2)  # ones padding\n    yp = numpy.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded\n    return numpy.convolve(yp, numpy.ones(nf) / nf, mode='valid')  # y-smoothed\n\n\ndef compute_ap(tp, conf, pred_cls, target_cls, eps=1e-16):\n    \"\"\"\n    Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Object-ness value from 0-1 (nparray).\n        pred_cls:  Predicted object classes (nparray).\n        target_cls:  True object classes (nparray).\n    # Returns\n        The average precision\n    \"\"\"\n    # Sort by object-ness\n    i = numpy.argsort(-conf)\n    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n\n    # Find unique classes\n    unique_classes, nt = numpy.unique(target_cls, return_counts=True)\n    nc = unique_classes.shape[0]  # number of classes, number of detections\n\n    # Create Precision-Recall curve and compute AP for each class\n    p = numpy.zeros((nc, 1000))\n    r = numpy.zeros((nc, 1000))\n    ap = numpy.zeros((nc, tp.shape[1]))\n    px, py = numpy.linspace(0, 1, 1000), []  # for plotting\n    for ci, c in enumerate(unique_classes):\n        i = pred_cls == c\n        nl = nt[ci]  # number of labels\n        no = i.sum()  # number of outputs\n        if no == 0 or nl == 0:\n            continue\n\n        # Accumulate FPs and TPs\n        fpc = (1 - tp[i]).cumsum(0)\n        tpc = tp[i].cumsum(0)\n\n        # Recall\n        recall = tpc / (nl + eps)  # recall curve\n        # negative x, xp because xp decreases\n        r[ci] = numpy.interp(-px, -conf[i], recall[:, 0], left=0)\n\n        # Precision\n        precision = tpc / (tpc + fpc)  # precision curve\n        p[ci] = numpy.interp(-px, -conf[i], precision[:, 0], left=1)  # p at pr_score\n\n        # AP from recall-precision curve\n        for j in range(tp.shape[1]):\n            m_rec = numpy.concatenate(([0.0], recall[:, j], [1.0]))\n            m_pre = numpy.concatenate(([1.0], precision[:, j], [0.0]))\n\n            # Compute the precision envelope\n            m_pre = numpy.flip(numpy.maximum.accumulate(numpy.flip(m_pre)))\n\n            # Integrate area under curve\n            x = numpy.linspace(0, 1, 101)  # 101-point interp (COCO)\n            ap[ci, j] = numpy.trapz(numpy.interp(x, m_rec, m_pre), x)  # integrate\n\n    # Compute F1 (harmonic mean of precision and recall)\n    f1 = 2 * p * r / (p + r + eps)\n\n    i = smooth(f1.mean(0), 0.1).argmax()  # max F1 index\n    p, r, f1 = p[:, i], r[:, i], f1[:, i]\n    tp = (r * nt).round()  # true positives\n    fp = (tp / (p + eps) - tp).round()  # false positives\n    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n    m_pre, m_rec = p.mean(), r.mean()\n    map50, mean_ap = ap50.mean(), ap.mean()\n    return tp, fp, m_pre, m_rec, map50, mean_ap\n\n\ndef strip_optimizer(filename):\n    x = torch.load(filename, map_location=torch.device('cuda'), weights_only=False)\n\n    x['model'].half()  # to FP16\n    for p in x['model'].parameters():\n        p.requires_grad = False\n    torch.save(x, filename)\n\n\ndef clip_gradients(model, max_norm=10.0):\n    parameters = model.parameters()\n    torch.nn.utils.clip_grad_norm_(parameters, max_norm=max_norm)\n\n\nclass EMA:\n    \"\"\"\n    Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models\n    Keeps a moving average of everything in the model state_dict (parameters and buffers)\n    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    \"\"\"\n\n    def __init__(self, model, decay=0.9999, tau=2000, updates=0):\n        # Create EMA\n        self.ema = copy.deepcopy(model).eval()  # FP32 EMA\n        self.updates = updates  # number of EMA updates\n        # decay exponential ramp (to help early epochs)\n        self.decay = lambda x: decay * (1 - math.exp(-x / tau))\n        for p in self.ema.parameters():\n            p.requires_grad_(False)\n\n    def update(self, model):\n        if hasattr(model, 'module'):\n            model = model.module\n        # Update EMA parameters\n        with torch.no_grad():\n            self.updates += 1\n            d = self.decay(self.updates)\n\n            msd = model.state_dict()  # model state_dict\n            for k, v in self.ema.state_dict().items():\n                if v.dtype.is_floating_point:\n                    v *= d\n                    v += (1 - d) * msd[k].detach()\n\n\nclass AverageMeter:\n    def __init__(self):\n        self.num = 0\n        self.sum = 0\n        self.avg = 0\n\n    def update(self, v, n):\n        if not math.isnan(float(v)):\n            self.num = self.num + n\n            self.sum = self.sum + v * n\n            self.avg = self.sum / self.num\n\n\nclass ComputeLoss:\n    def __init__(self, model, params):\n        super().__init__()\n        if hasattr(model, 'module'):\n            model = model.module\n\n        device = next(model.parameters()).device  # get model device\n\n        m = model.head  # Head() module\n        self.bce = torch.nn.BCEWithLogitsLoss(reduction='none')\n        self.stride = m.stride  # model strides\n        self.nc = m.nc  # number of classes\n        self.no = m.no\n        self.device = device\n        self.params = params\n\n        # task aligned assigner\n        self.top_k = 10\n        self.alpha = 0.5\n        self.beta = 6.0\n        self.eps = 1e-9\n\n        self.bs = 1\n        self.num_max_boxes = 0\n        # DFL Loss params\n        self.dfl_ch = m.dfl.ch\n        self.project = torch.arange(self.dfl_ch, dtype=torch.float, device=device)\n\n    def __call__(self, outputs, targets):\n        x = outputs[1] if isinstance(outputs, tuple) else outputs\n        output = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], 2)\n        pred_output, pred_scores = output.split((4 * self.dfl_ch, self.nc), 1)\n\n        pred_output = pred_output.permute(0, 2, 1).contiguous()\n        pred_scores = pred_scores.permute(0, 2, 1).contiguous()\n\n        size = torch.tensor(x[0].shape[2:], dtype=pred_scores.dtype, device=self.device)\n        size = size * self.stride[0]\n\n        anchor_points, stride_tensor = make_anchors(x, self.stride, 0.5)\n\n        # targets\n        if targets.shape[0] == 0:\n            gt = torch.zeros(pred_scores.shape[0], 0, 5, device=self.device)\n        else:\n            i = targets[:, 0]  # image index\n            _, counts = i.unique(return_counts=True)\n            gt = torch.zeros(pred_scores.shape[0], counts.max(), 5, device=self.device)\n            for j in range(pred_scores.shape[0]):\n                matches = i == j\n                n = matches.sum()\n                if n:\n                    gt[j, :n] = targets[matches, 1:]\n            gt[..., 1:5] = wh2xy(gt[..., 1:5].mul_(size[[1, 0, 1, 0]]))\n\n        gt_labels, gt_bboxes = gt.split((1, 4), 2)  # cls, xyxy\n        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0)\n\n        # boxes\n        b, a, c = pred_output.shape\n        pred_bboxes = pred_output.view(b, a, 4, c // 4).softmax(3)\n        pred_bboxes = pred_bboxes.matmul(self.project.type(pred_bboxes.dtype))\n\n        a, b = torch.split(pred_bboxes, 2, -1)\n        pred_bboxes = torch.cat((anchor_points - a, anchor_points + b), -1)\n\n        scores = pred_scores.detach().sigmoid()\n        bboxes = (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype)\n        target_bboxes, target_scores, fg_mask = self.assign(scores, bboxes,\n                                                            gt_labels, gt_bboxes, mask_gt,\n                                                            anchor_points * stride_tensor)\n\n        target_bboxes /= stride_tensor\n        target_scores_sum = target_scores.sum()\n\n        # cls loss\n        loss_cls = self.bce(pred_scores, target_scores.to(pred_scores.dtype))\n        loss_cls = loss_cls.sum() / target_scores_sum\n\n        # box loss\n        loss_box = torch.zeros(1, device=self.device)\n        loss_dfl = torch.zeros(1, device=self.device)\n        if fg_mask.sum():\n            # IoU loss\n            weight = torch.masked_select(target_scores.sum(-1), fg_mask).unsqueeze(-1)\n            loss_box = self.iou(pred_bboxes[fg_mask], target_bboxes[fg_mask])\n            loss_box = ((1.0 - loss_box) * weight).sum() / target_scores_sum\n            # DFL loss\n            a, b = torch.split(target_bboxes, 2, -1)\n            target_lt_rb = torch.cat((anchor_points - a, b - anchor_points), -1)\n            target_lt_rb = target_lt_rb.clamp(0, self.dfl_ch - 1.01)  # distance (left_top, right_bottom)\n            loss_dfl = self.df_loss(pred_output[fg_mask].view(-1, self.dfl_ch), target_lt_rb[fg_mask])\n            loss_dfl = (loss_dfl * weight).sum() / target_scores_sum\n\n        loss_cls *= self.params['cls']\n        loss_box *= self.params['box']\n        loss_dfl *= self.params['dfl']\n        return loss_cls + loss_box + loss_dfl  # loss(cls, box, dfl)\n\n    @torch.no_grad()\n    def assign(self, pred_scores, pred_bboxes, true_labels, true_bboxes, true_mask, anchors):\n        \"\"\"\n        Task-aligned One-stage Object Detection assigner\n        \"\"\"\n        self.bs = pred_scores.size(0)\n        self.num_max_boxes = true_bboxes.size(1)\n\n        if self.num_max_boxes == 0:\n            device = true_bboxes.device\n            return (torch.full_like(pred_scores[..., 0], self.nc).to(device),\n                    torch.zeros_like(pred_bboxes).to(device),\n                    torch.zeros_like(pred_scores).to(device),\n                    torch.zeros_like(pred_scores[..., 0]).to(device),\n                    torch.zeros_like(pred_scores[..., 0]).to(device))\n\n        i = torch.zeros([2, self.bs, self.num_max_boxes], dtype=torch.long)\n        i[0] = torch.arange(end=self.bs).view(-1, 1).repeat(1, self.num_max_boxes)\n        i[1] = true_labels.long().squeeze(-1)\n\n        overlaps = self.iou(true_bboxes.unsqueeze(2), pred_bboxes.unsqueeze(1))\n        overlaps = overlaps.squeeze(3).clamp(0)\n        align_metric = pred_scores[i[0], :, i[1]].pow(self.alpha) * overlaps.pow(self.beta)\n        bs, n_boxes, _ = true_bboxes.shape\n        lt, rb = true_bboxes.view(-1, 1, 4).chunk(2, 2)  # left-top, right-bottom\n        bbox_deltas = torch.cat((anchors[None] - lt, rb - anchors[None]), dim=2)\n        mask_in_gts = bbox_deltas.view(bs, n_boxes, anchors.shape[0], -1).amin(3).gt_(1e-9)\n        metrics = align_metric * mask_in_gts\n        top_k_mask = true_mask.repeat([1, 1, self.top_k]).bool()\n        num_anchors = metrics.shape[-1]\n        top_k_metrics, top_k_indices = torch.topk(metrics, self.top_k, dim=-1, largest=True)\n        if top_k_mask is None:\n            top_k_mask = (top_k_metrics.max(-1, keepdim=True) > self.eps).tile([1, 1, self.top_k])\n        top_k_indices = torch.where(top_k_mask, top_k_indices, 0)\n        is_in_top_k = one_hot(top_k_indices, num_anchors).sum(-2)\n        # filter invalid boxes\n        is_in_top_k = torch.where(is_in_top_k > 1, 0, is_in_top_k)\n        mask_top_k = is_in_top_k.to(metrics.dtype)\n        # merge all mask to a final mask, (b, max_num_obj, h*w)\n        mask_pos = mask_top_k * mask_in_gts * true_mask\n\n        fg_mask = mask_pos.sum(-2)\n        if fg_mask.max() > 1:  # one anchor is assigned to multiple gt_bboxes\n            mask_multi_gts = (fg_mask.unsqueeze(1) > 1).repeat([1, self.num_max_boxes, 1])\n            max_overlaps_idx = overlaps.argmax(1)\n            is_max_overlaps = one_hot(max_overlaps_idx, self.num_max_boxes)\n            is_max_overlaps = is_max_overlaps.permute(0, 2, 1).to(overlaps.dtype)\n            mask_pos = torch.where(mask_multi_gts, is_max_overlaps, mask_pos)\n            fg_mask = mask_pos.sum(-2)\n        # find each grid serve which gt(index)\n        target_gt_idx = mask_pos.argmax(-2)  # (b, h*w)\n\n        # assigned target labels, (b, 1)\n        batch_index = torch.arange(end=self.bs,\n                                   dtype=torch.int64,\n                                   device=true_labels.device)[..., None]\n        target_gt_idx = target_gt_idx + batch_index * self.num_max_boxes\n        target_labels = true_labels.long().flatten()[target_gt_idx]\n\n        # assigned target boxes\n        target_bboxes = true_bboxes.view(-1, 4)[target_gt_idx]\n\n        # assigned target scores\n        target_labels.clamp(0)\n        target_scores = one_hot(target_labels, self.nc)\n        fg_scores_mask = fg_mask[:, :, None].repeat(1, 1, self.nc)\n        target_scores = torch.where(fg_scores_mask > 0, target_scores, 0)\n\n        # normalize\n        align_metric *= mask_pos\n        pos_align_metrics = align_metric.amax(axis=-1, keepdim=True)\n        pos_overlaps = (overlaps * mask_pos).amax(axis=-1, keepdim=True)\n        norm_align_metric = (align_metric * pos_overlaps / (pos_align_metrics + self.eps)).amax(-2)\n        norm_align_metric = norm_align_metric.unsqueeze(-1)\n        target_scores = target_scores * norm_align_metric\n\n        return target_bboxes, target_scores, fg_mask.bool()\n\n    @staticmethod\n    def df_loss(pred_dist, target):\n        # Return sum of left and right DFL losses\n        # Distribution Focal Loss https://ieeexplore.ieee.org/document/9792391\n        tl = target.long()  # target left\n        tr = tl + 1  # target right\n        wl = tr - target  # weight left\n        wr = 1 - wl  # weight right\n        l_loss = cross_entropy(pred_dist, tl.view(-1), reduction=\"none\").view(tl.shape)\n        r_loss = cross_entropy(pred_dist, tr.view(-1), reduction=\"none\").view(tl.shape)\n        return (l_loss * wl + r_loss * wr).mean(-1, keepdim=True)\n\n    @staticmethod\n    def iou(box1, box2, eps=1e-7):\n        # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4)\n\n        # Get the coordinates of bounding boxes\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1.chunk(4, -1)\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2.chunk(4, -1)\n        w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1 + eps\n        w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1 + eps\n\n        # Intersection area\n        area1 = b1_x2.minimum(b2_x2) - b1_x1.maximum(b2_x1)\n        area2 = b1_y2.minimum(b2_y2) - b1_y1.maximum(b2_y1)\n        intersection = area1.clamp(0) * area2.clamp(0)\n\n        # Union Area\n        union = w1 * h1 + w2 * h2 - intersection + eps\n\n        # IoU\n        iou = intersection / union\n        cw = b1_x2.maximum(b2_x2) - b1_x1.minimum(b2_x1)  # convex width\n        ch = b1_y2.maximum(b2_y2) - b1_y1.minimum(b2_y1)  # convex height\n        # Complete IoU https://arxiv.org/abs/1911.08287v1\n        c2 = cw ** 2 + ch ** 2 + eps  # convex diagonal squared\n        # center dist ** 2\n        rho2 = ((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** 2 + (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** 2) / 4\n        # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n        v = (4 / math.pi ** 2) * (torch.atan(w2 / h2) - torch.atan(w1 / h1)).pow(2)\n        with torch.no_grad():\n            alpha = v / (v - iou + (1 + eps))\n        return iou - (rho2 / c2 + v * alpha)  # CIoU","metadata":{"id":"izCZhvAKC92F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"34801ade-0954-4cc6-ab6f-37b003caa95b","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.908044Z","iopub.execute_input":"2025-05-06T12:56:30.908691Z","iopub.status.idle":"2025-05-06T12:56:30.929518Z","shell.execute_reply.started":"2025-05-06T12:56:30.908663Z","shell.execute_reply":"2025-05-06T12:56:30.928848Z"}},"outputs":[{"name":"stdout","text":"Writing utils/util.py\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# nets","metadata":{"id":"en5AbGCXFpcj"}},{"cell_type":"code","source":"import os\n\n# Create the directory if it doesn't exist\nos.makedirs(\"nets\", exist_ok=True)\n \n\n\n","metadata":{"id":"YknSrS8JwUCW","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.930185Z","iopub.execute_input":"2025-05-06T12:56:30.930353Z","iopub.status.idle":"2025-05-06T12:56:30.945274Z","shell.execute_reply.started":"2025-05-06T12:56:30.930339Z","shell.execute_reply":"2025-05-06T12:56:30.944793Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"%%writefile nets/nn.py\n\n\n\n\n\n\nimport math\n\nimport torch\n\nfrom utils.util import make_anchors\n\n\ndef pad(k, p=None, d=1):\n    if d > 1:\n        k = d * (k - 1) + 1\n    if p is None:\n        p = k // 2\n    return p\n\n\ndef fuse_conv(conv, norm):\n    fused_conv = torch.nn.Conv2d(conv.in_channels,\n                                 conv.out_channels,\n                                 kernel_size=conv.kernel_size,\n                                 stride=conv.stride,\n                                 padding=conv.padding,\n                                 groups=conv.groups,\n                                 bias=True).requires_grad_(False).to(conv.weight.device)\n\n    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n    w_norm = torch.diag(norm.weight.div(torch.sqrt(norm.eps + norm.running_var)))\n    fused_conv.weight.copy_(torch.mm(w_norm, w_conv).view(fused_conv.weight.size()))\n\n    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n    b_norm = norm.bias - norm.weight.mul(norm.running_mean).div(torch.sqrt(norm.running_var + norm.eps))\n    fused_conv.bias.copy_(torch.mm(w_norm, b_conv.reshape(-1, 1)).reshape(-1) + b_norm)\n\n    return fused_conv\n\n\nclass Conv(torch.nn.Module):\n    def __init__(self, in_ch, out_ch, k=1, s=1, p=None, d=1, g=1):\n        super().__init__()\n        self.conv = torch.nn.Conv2d(in_ch, out_ch, k, s, pad(k, p, d), d, g, False)\n        self.norm = torch.nn.BatchNorm2d(out_ch, 0.001, 0.03)\n        self.relu = torch.nn.SiLU(inplace=True)\n\n    def forward(self, x):\n        return self.relu(self.norm(self.conv(x)))\n\n    def fuse_forward(self, x):\n        return self.relu(self.conv(x))\n\n\nclass Residual(torch.nn.Module):\n    def __init__(self, ch, add=True):\n        super().__init__()\n        self.add_m = add\n        self.res_m = torch.nn.Sequential(Conv(ch, ch, 3),\n                                         Conv(ch, ch, 3))\n\n    def forward(self, x):\n        return self.res_m(x) + x if self.add_m else self.res_m(x)\n\n\nclass CSP(torch.nn.Module):\n    def __init__(self, in_ch, out_ch, n=1, add=True):\n        super().__init__()\n        self.conv1 = Conv(in_ch, out_ch // 2)\n        self.conv2 = Conv(in_ch, out_ch // 2)\n        self.conv3 = Conv((2 + n) * out_ch // 2, out_ch)\n        self.res_m = torch.nn.ModuleList(Residual(out_ch // 2, add) for _ in range(n))\n\n    def forward(self, x):\n        y = [self.conv1(x), self.conv2(x)]\n        y.extend(m(y[-1]) for m in self.res_m)\n        return self.conv3(torch.cat(y, dim=1))\n\n\nclass SPP(torch.nn.Module):\n    def __init__(self, in_ch, out_ch, k=5):\n        super().__init__()\n        self.conv1 = Conv(in_ch, in_ch // 2)\n        self.conv2 = Conv(in_ch * 2, out_ch)\n        self.res_m = torch.nn.MaxPool2d(k, 1, k // 2)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        y1 = self.res_m(x)\n        y2 = self.res_m(y1)\n        return self.conv2(torch.cat([x, y1, y2, self.res_m(y2)], 1))\n\n\nclass DarkNet(torch.nn.Module):\n    def __init__(self, width, depth):\n        super().__init__()\n        p1 = [Conv(width[0], width[1], 3, 2)]\n        p2 = [Conv(width[1], width[2], 3, 2),\n              CSP(width[2], width[2], depth[0])]\n        p3 = [Conv(width[2], width[3], 3, 2),\n              CSP(width[3], width[3], depth[1])]\n        p4 = [Conv(width[3], width[4], 3, 2),\n              CSP(width[4], width[4], depth[2])]\n        p5 = [Conv(width[4], width[5], 3, 2),\n              CSP(width[5], width[5], depth[0]),\n              SPP(width[5], width[5])]\n\n        self.p1 = torch.nn.Sequential(*p1)\n        self.p2 = torch.nn.Sequential(*p2)\n        self.p3 = torch.nn.Sequential(*p3)\n        self.p4 = torch.nn.Sequential(*p4)\n        self.p5 = torch.nn.Sequential(*p5)\n\n    def forward(self, x):\n        p1 = self.p1(x)\n        p2 = self.p2(p1)\n        p3 = self.p3(p2)\n        p4 = self.p4(p3)\n        p5 = self.p5(p4)\n        return p3, p4, p5\n\n\nclass DarkFPN(torch.nn.Module):\n    def __init__(self, width, depth):\n        super().__init__()\n        self.up = torch.nn.Upsample(None, 2)\n        self.h1 = CSP(width[4] + width[5], width[4], depth[0], False)\n        self.h2 = CSP(width[3] + width[4], width[3], depth[0], False)\n        self.h3 = Conv(width[3], width[3], 3, 2)\n        self.h4 = CSP(width[3] + width[4], width[4], depth[0], False)\n        self.h5 = Conv(width[4], width[4], 3, 2)\n        self.h6 = CSP(width[4] + width[5], width[5], depth[0], False)\n\n    def forward(self, x):\n        p3, p4, p5 = x\n        h1 = self.h1(torch.cat([self.up(p5), p4], 1))\n        h2 = self.h2(torch.cat([self.up(h1), p3], 1))\n        h4 = self.h4(torch.cat([self.h3(h2), h1], 1))\n        h6 = self.h6(torch.cat([self.h5(h4), p5], 1))\n        return h2, h4, h6\n\n\nclass DFL(torch.nn.Module):\n    # Integral module of Distribution Focal Loss (DFL)\n    # Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n    def __init__(self, ch=16):\n        super().__init__()\n        self.ch = ch\n        self.conv = torch.nn.Conv2d(ch, 1, 1, bias=False).requires_grad_(False)\n        x = torch.arange(ch, dtype=torch.float).view(1, ch, 1, 1)\n        self.conv.weight.data[:] = torch.nn.Parameter(x)\n\n    def forward(self, x):\n        b, c, a = x.shape\n        x = x.view(b, 4, self.ch, a).transpose(2, 1)\n        return self.conv(x.softmax(1)).view(b, 4, a)\n\n\nclass Head(torch.nn.Module):\n    anchors = torch.empty(0)\n    strides = torch.empty(0)\n\n    def __init__(self, nc=80, filters=()):\n        super().__init__()\n        self.ch = 16  # DFL channels\n        self.nc = nc  # number of classes\n        self.nl = len(filters)  # number of detection layers\n        self.no = nc + self.ch * 4  # number of outputs per anchor\n        self.stride = torch.zeros(self.nl)  # strides computed during build\n\n        c1 = max(filters[0], self.nc)\n        c2 = max((filters[0] // 4, self.ch * 4))\n\n        self.dfl = DFL(self.ch)\n        self.cls = torch.nn.ModuleList(torch.nn.Sequential(Conv(x, c1, 3),\n                                                           Conv(c1, c1, 3),\n                                                           torch.nn.Conv2d(c1, self.nc, 1)) for x in filters)\n        self.box = torch.nn.ModuleList(torch.nn.Sequential(Conv(x, c2, 3),\n                                                           Conv(c2, c2, 3),\n                                                           torch.nn.Conv2d(c2, 4 * self.ch, 1)) for x in filters)\n\n    def forward(self, x):\n        for i in range(self.nl):\n            x[i] = torch.cat((self.box[i](x[i]), self.cls[i](x[i])), 1)\n        if self.training:\n            return x\n        self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))\n\n        x = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], 2)\n        box, cls = x.split((self.ch * 4, self.nc), 1)\n        a, b = torch.split(self.dfl(box), 2, 1)\n        a = self.anchors.unsqueeze(0) - a\n        b = self.anchors.unsqueeze(0) + b\n        box = torch.cat(((a + b) / 2, b - a), 1)\n        return torch.cat((box * self.strides, cls.sigmoid()), 1)\n\n    def initialize_biases(self):\n        # Initialize biases\n        # WARNING: requires stride availability\n        m = self\n        for a, b, s in zip(m.box, m.cls, m.stride):\n            a[-1].bias.data[:] = 1.0  # box\n            # cls (.01 objects, 80 classes, 640 img)\n            b[-1].bias.data[:m.nc] = math.log(5 / m.nc / (640 / s) ** 2)\n\n\nclass YOLO(torch.nn.Module):\n    def __init__(self, width, depth, num_classes):\n        super().__init__()\n        self.net = DarkNet(width, depth)\n        self.fpn = DarkFPN(width, depth)\n\n        img_dummy = torch.zeros(1, 3, 256, 256)\n        self.head = Head(num_classes, (width[3], width[4], width[5]))\n        self.head.stride = torch.tensor([256 / x.shape[-2] for x in self.forward(img_dummy)])\n        self.stride = self.head.stride\n        self.head.initialize_biases()\n\n    def forward(self, x):\n        x = self.net(x)\n        x = self.fpn(x)\n        return self.head(list(x))\n\n    def fuse(self):\n        for m in self.modules():\n            if type(m) is Conv and hasattr(m, 'norm'):\n                m.conv = fuse_conv(m.conv, m.norm)\n                m.forward = m.fuse_forward\n                delattr(m, 'norm')\n        return self\n\n\ndef yolo_v8_n(num_classes: int = 80):\n    depth = [1, 2, 2]\n    width = [3, 16, 32, 64, 128, 256]\n    return YOLO(width, depth, num_classes)\n\n\ndef yolo_v8_s(num_classes: int = 80):\n    depth = [1, 2, 2]\n    width = [3, 32, 64, 128, 256, 512]\n    return YOLO(width, depth, num_classes)\n\n\ndef yolo_v8_m(num_classes: int = 80):\n    depth = [2, 4, 4]\n    width = [3, 48, 96, 192, 384, 576]\n    return YOLO(width, depth, num_classes)\n\n\ndef yolo_v8_l(num_classes: int = 80):\n    depth = [3, 6, 6]\n    width = [3, 64, 128, 256, 512, 512]\n    return YOLO(width, depth, num_classes)\n\n\ndef yolo_v8_x(num_classes: int = 80):\n    depth = [3, 6, 6]\n    width = [3, 80, 160, 320, 640, 640]\n    return YOLO(width, depth, num_classes)","metadata":{"id":"Ppv6-iXzFh1D","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ea571c4-7076-43eb-fe02-82d6de08951c","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.945967Z","iopub.execute_input":"2025-05-06T12:56:30.946123Z","iopub.status.idle":"2025-05-06T12:56:30.961582Z","shell.execute_reply.started":"2025-05-06T12:56:30.946110Z","shell.execute_reply":"2025-05-06T12:56:30.960837Z"}},"outputs":[{"name":"stdout","text":"Writing nets/nn.py\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"Jw3GNNH5Fh3s","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.962348Z","iopub.execute_input":"2025-05-06T12:56:30.962712Z","iopub.status.idle":"2025-05-06T12:56:30.992634Z","shell.execute_reply.started":"2025-05-06T12:56:30.962688Z","shell.execute_reply":"2025-05-06T12:56:30.991939Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"id":"G19PZe_1tOgp","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# main","metadata":{"id":"u6vWT3kuIunE"}},{"cell_type":"code","source":"!pip install torchvision\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIbBcQhJM0S5","outputId":"9b5cd63b-169b-474a-c96e-c8fab469aabb","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:30.993391Z","iopub.execute_input":"2025-05-06T12:56:30.993603Z","iopub.status.idle":"2025-05-06T12:56:34.995243Z","shell.execute_reply.started":"2025-05-06T12:56:30.993588Z","shell.execute_reply":"2025-05-06T12:56:34.994585Z"}},"outputs":[{"name":"stdout","text":"Collecting torchvision\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.2.5)\nRequirement already satisfied: torch==2.7.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.7.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (4.13.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (1.11.1.6)\nRequirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.3.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->torchvision) (75.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\nDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torchvision-0.22.0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%writefile main.py\n\nimport argparse\nimport copy\nimport csv\nimport os\nimport warnings\n\nimport numpy\nimport torch\nimport tqdm\nimport yaml\nfrom torch.utils import data\n\nfrom nets import nn\nfrom utils import util\nfrom utils.dataset import Dataset\n\nwarnings.filterwarnings(\"ignore\")\n\n\ndef learning_rate(args, params):\n    def fn(x):\n        return (1 - x / args.epochs) * (1.0 - params['lrf']) + params['lrf']\n\n    return fn\n\n\ndef train(args, params):\n    # Model\n    model = nn.yolo_v8_n(len(params['names'].values())).cuda()\n\n    # Optimizer\n    accumulate = max(round(64 / (args.batch_size * args.world_size)), 1)\n    params['weight_decay'] *= args.batch_size * args.world_size * accumulate / 64\n\n    p = [], [], []\n    for v in model.modules():\n        if hasattr(v, 'bias') and isinstance(v.bias, torch.nn.Parameter):\n            p[2].append(v.bias)\n        if isinstance(v, torch.nn.BatchNorm2d):\n            p[1].append(v.weight)\n        elif hasattr(v, 'weight') and isinstance(v.weight, torch.nn.Parameter):\n            p[0].append(v.weight)\n\n    optimizer = torch.optim.SGD(p[2], params['lr0'], params['momentum'], nesterov=True)\n\n    optimizer.add_param_group({'params': p[0], 'weight_decay': params['weight_decay']})\n    optimizer.add_param_group({'params': p[1]})\n    del p\n\n    # Scheduler\n    lr = learning_rate(args, params)\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr, last_epoch=-1)\n\n    # EMA\n    \n    #if (epoch + 1) % 50 == 0:\n    if args.local_rank == 0:\n        ema = util.EMA(model)\n    else:\n        None\n\n\n  \n    # For training images\n    filenames = []\n    with open('/kaggle/input/d/anitatasnimproma/tinycoco1/train2017.txt') as reader:\n        for line in reader:\n            # Extract filename only\n            fname = line.strip().split('/')[-1]\n            # Reconstruct the correct path\n            full_path = f'/kaggle/input/d/anitatasnimproma/tinycoco1/images/train2017/{fname}'\n            filenames.append(full_path)\n\n    \n    dataset = Dataset(filenames, args.input_size, params, True)\n\n \n\n    if args.world_size <= 1:\n        sampler = None\n    else:\n        sampler = data.distributed.DistributedSampler(dataset)\n\n    loader = data.DataLoader(dataset, args.batch_size, sampler is None, sampler,\n                             num_workers=8, pin_memory=True, collate_fn=Dataset.collate_fn)\n\n    if args.world_size > 1:\n        # DDP mode\n        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n        model = torch.nn.parallel.DistributedDataParallel(module=model,\n                                                          device_ids=[args.local_rank],\n                                                          output_device=args.local_rank)\n\n    # Start training\n    best = 0\n    num_batch = len(loader)\n    amp_scale = torch.cuda.amp.GradScaler()\n    criterion = util.ComputeLoss(model, params)\n    num_warmup = max(round(params['warmup_epochs'] * num_batch), 1000)\n\n\n    os.makedirs(\"weights\", exist_ok=True)\n \n\n\n    \n    with open('weights/step.csv', 'w') as f:\n        if args.local_rank == 0:\n            writer = csv.DictWriter(f, fieldnames=['epoch', 'mAP@50', 'mAP'])\n            writer.writeheader()\n        for epoch in range(args.epochs):\n            model.train()\n\n            if args.epochs - epoch == 10:\n                loader.dataset.mosaic = False\n\n            m_loss = util.AverageMeter()\n            if args.world_size > 1:\n                sampler.set_epoch(epoch)\n            p_bar = enumerate(loader)\n            if (epoch + 1) % 1 == 0:\n                if args.local_rank == 0:\n                    print(('\\n' + '%10s' * 3) % ('epoch', 'memory', 'loss'))\n            if (epoch + 1) % 1 == 0:\n                if args.local_rank == 0:\n                    p_bar = tqdm.tqdm(p_bar, total=num_batch)  # progress bar\n\n            optimizer.zero_grad()\n\n            for i, (samples, targets, _) in p_bar:\n                x = i + num_batch * epoch  # number of iterations\n                samples = samples.cuda().float() / 255\n                targets = targets.cuda()\n\n                # Warmup\n                if x <= num_warmup:\n                    xp = [0, num_warmup]\n                    fp = [1, 64 / (args.batch_size * args.world_size)]\n                    accumulate = max(1, numpy.interp(x, xp, fp).round())\n                    for j, y in enumerate(optimizer.param_groups):\n                        if j == 0:\n                            fp = [params['warmup_bias_lr'], y['initial_lr'] * lr(epoch)]\n                        else:\n                            fp = [0.0, y['initial_lr'] * lr(epoch)]\n                        y['lr'] = numpy.interp(x, xp, fp)\n                        if 'momentum' in y:\n                            fp = [params['warmup_momentum'], params['momentum']]\n                            y['momentum'] = numpy.interp(x, xp, fp)\n\n                # Forward\n                with torch.cuda.amp.autocast():\n                    outputs = model(samples)  # forward\n                loss = criterion(outputs, targets)\n\n                m_loss.update(loss.item(), samples.size(0))\n\n                loss *= args.batch_size  # loss scaled by batch_size\n                loss *= args.world_size  # gradient averaged between devices in DDP mode\n\n                # Backward\n                amp_scale.scale(loss).backward()\n\n                # Optimize\n                if x % accumulate == 0:\n                    amp_scale.unscale_(optimizer)  # unscale gradients\n                    util.clip_gradients(model)  # clip gradients\n                    amp_scale.step(optimizer)  # optimizer.step\n                    amp_scale.update()\n                    optimizer.zero_grad()\n                    if ema:\n                        ema.update(model)\n                    torch.cuda.empty_cache()\n\n                # Log\n                if (epoch + 1) % 1 == 0:\n                    if args.local_rank == 0:\n                        memory = f'{torch.cuda.memory_reserved() / 1E9:.3g}G'  # (GB)\n                        s = ('%10s' * 2 + '%10.4g') % (f'{epoch + 1}/{args.epochs}', memory, m_loss.avg)\n                        p_bar.set_description(s)\n\n                del loss\n                del outputs\n                #torch.cuda.empty_cache()\n\n            # Scheduler\n            scheduler.step()\n            if (epoch + 1) % 1 == 0:\n                if args.local_rank == 0:\n                    # mAP\n                    last = test(args, params, ema.ema)\n                    writer.writerow({'mAP': str(f'{last[1]:.3f}'),\n                                     'epoch': str(epoch + 1).zfill(3),\n                                     'mAP@50': str(f'{last[0]:.3f}')})\n                    f.flush()\n    \n                    # Update best mAP\n                    if last[1] > best:\n                        best = last[1]\n    \n                    # Save model\n                    ckpt = {'model': copy.deepcopy(ema.ema).half()}\n    \n                    # Save last, best and delete\n                    torch.save(ckpt, './weights/last.pt')\n                    if best == last[1]:\n                        torch.save(ckpt, './weights/best.pt')\n                    del ckpt\n                    torch.cuda.empty_cache()\n\n    if args.local_rank == 0:\n        util.strip_optimizer('./weights/best.pt')  # strip optimizers\n        util.strip_optimizer('./weights/last.pt')  # strip optimizers\n\n    torch.cuda.empty_cache()\n\n\n@torch.no_grad()\ndef test(args, params, model=None):\n\n\n    filenames = []\n    # For validation images\n \n    with open('/kaggle/input/d/anitatasnimproma/tinycoco1/val2017.txt') as reader:\n        for line in reader:\n            fname = line.strip().split('/')[-1]\n            full_path = f'/kaggle/input/d/anitatasnimproma/tinycoco1/images/val2017/{fname}'\n            filenames.append(full_path)\n\n \n    \n    dataset = Dataset(filenames, args.input_size, params, False)\n\n    \n \n\n                      \n    loader = data.DataLoader(dataset, 8, False, num_workers=8,\n                             pin_memory=True, collate_fn=Dataset.collate_fn)\n\n    if model is None:\n        model = torch.load('./weights/best.pt', map_location='cuda', weights_only=False)['model'].float()\n\n\n    model.half()\n    model.eval()\n\n    # Configure\n    iou_v = torch.linspace(0.5, 0.95, 10).cuda()  # iou vector for mAP@0.5:0.95\n    n_iou = iou_v.numel()\n\n    m_pre = 0.\n    m_rec = 0.\n    map50 = 0.\n    mean_ap = 0.\n    metrics = []\n    p_bar = tqdm.tqdm(loader, desc=('%10s' * 3) % ('precision', 'recall', 'mAP'))\n    for samples, targets, shapes in p_bar:\n        samples = samples.cuda()\n        targets = targets.cuda()\n        samples = samples.half()  # uint8 to fp16/32\n        samples = samples / 255  # 0 - 255 to 0.0 - 1.0\n        _, _, height, width = samples.shape  # batch size, channels, height, width\n\n        # Inference\n        outputs = model(samples)\n\n        # NMS\n        targets[:, 2:] *= torch.tensor((width, height, width, height)).cuda()  # to pixels\n        outputs = util.non_max_suppression(outputs, 0.001, 0.65)\n\n        # Metrics\n        for i, output in enumerate(outputs):\n            labels = targets[targets[:, 0] == i, 1:]\n            correct = torch.zeros(output.shape[0], n_iou, dtype=torch.bool).cuda()\n\n            if output.shape[0] == 0:\n                if labels.shape[0]:\n                    metrics.append((correct, *torch.zeros((3, 0)).cuda()))\n                continue\n\n            detections = output.clone()\n            util.scale(detections[:, :4], samples[i].shape[1:], shapes[i][0], shapes[i][1])\n\n            # Evaluate\n            if labels.shape[0]:\n                tbox = labels[:, 1:5].clone()  # target boxes\n                tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n                tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n                tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n                tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n                util.scale(tbox, samples[i].shape[1:], shapes[i][0], shapes[i][1])\n\n                correct = numpy.zeros((detections.shape[0], iou_v.shape[0]))\n                correct = correct.astype(bool)\n\n                t_tensor = torch.cat((labels[:, 0:1], tbox), 1)\n                iou = util.box_iou(t_tensor[:, 1:], detections[:, :4])\n                correct_class = t_tensor[:, 0:1] == detections[:, 5]\n                for j in range(len(iou_v)):\n                    x = torch.where((iou >= iou_v[j]) & correct_class)\n                    if x[0].shape[0]:\n                        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1)\n                        matches = matches.cpu().numpy()\n                        if x[0].shape[0] > 1:\n                            matches = matches[matches[:, 2].argsort()[::-1]]\n                            matches = matches[numpy.unique(matches[:, 1], return_index=True)[1]]\n                            matches = matches[numpy.unique(matches[:, 0], return_index=True)[1]]\n                        correct[matches[:, 1].astype(int), j] = True\n                correct = torch.tensor(correct, dtype=torch.bool, device=iou_v.device)\n            metrics.append((correct, output[:, 4], output[:, 5], labels[:, 0]))\n\n    # Compute metrics\n    metrics = [torch.cat(x, 0).cpu().numpy() for x in zip(*metrics)]  # to numpy\n    if len(metrics) and metrics[0].any():\n        tp, fp, m_pre, m_rec, map50, mean_ap = util.compute_ap(*metrics)\n\n    # Print results\n    print('%10.3g' * 3 % (m_pre, m_rec, mean_ap))\n\n    # Return results\n    model.float()  # for training\n    torch.cuda.empty_cache()\n    return map50, mean_ap\n\n\n\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input-size', default=640, type=int)\n    parser.add_argument('--batch-size', default=32, type=int)\n    parser.add_argument('--local_rank', default=0, type=int)\n    parser.add_argument('--epochs', default=500, type=int)\n    parser.add_argument('--train', action='store_true')\n    parser.add_argument('--test', action='store_true')\n\n    args = parser.parse_args()\n\n    args.local_rank = int(os.getenv('LOCAL_RANK', 0))\n    args.world_size = int(os.getenv('WORLD_SIZE', 1))\n\n    if args.world_size > 1:\n        torch.cuda.set_device(device=args.local_rank)\n        torch.distributed.init_process_group(backend='nccl', init_method='env://')\n\n    if args.local_rank == 0:\n        if not os.path.exists('weights'):\n            os.makedirs('weights')\n\n    util.setup_seed()\n    util.setup_multi_processes()\n\n    with open(os.path.join('utils', 'args.yaml'), errors='ignore') as f:\n        params = yaml.safe_load(f)\n\n    if args.train:\n        train(args, params)\n    if args.test:\n        test(args, params)\n        torch.cuda.empty_cache()\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"id":"usJtZf-wFh6b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c45049c1-e694-42ae-e39e-dccd4fec275e","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:34.996202Z","iopub.execute_input":"2025-05-06T12:56:34.996402Z","iopub.status.idle":"2025-05-06T12:56:35.007298Z","shell.execute_reply.started":"2025-05-06T12:56:34.996384Z","shell.execute_reply":"2025-05-06T12:56:35.006567Z"}},"outputs":[{"name":"stdout","text":"Writing main.py\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print('abc')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:35.008110Z","iopub.execute_input":"2025-05-06T12:56:35.008345Z","iopub.status.idle":"2025-05-06T12:56:35.026901Z","shell.execute_reply.started":"2025-05-06T12:56:35.008324Z","shell.execute_reply":"2025-05-06T12:56:35.026367Z"}},"outputs":[{"name":"stdout","text":"abc\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"\n!python3 main.py --train\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tq5vc1E8Olhw","outputId":"874acd4a-efde-45f2-8d1a-a734416b1423","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:56:35.027550Z","iopub.execute_input":"2025-05-06T12:56:35.027757Z","iopub.status.idle":"2025-05-06T13:36:42.541474Z","shell.execute_reply.started":"2025-05-06T12:56:35.027733Z","shell.execute_reply":"2025-05-06T13:36:42.540738Z"}},"outputs":[{"name":"stdout","text":"\n     epoch    memory      loss\n     1/500    0.791G     13.39: 100%|█████████████| 4/4 [00:04<00:00,  1.10s/it]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 12.95it/s]\n         0         0         0\n\n     epoch    memory      loss\n     2/500     1.06G     13.31: 100%|█████████████| 4/4 [00:03<00:00,  1.23it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.96it/s]\n         0         0         0\n\n     epoch    memory      loss\n     3/500    0.904G     13.29: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 17.18it/s]\n         0         0         0\n\n     epoch    memory      loss\n     4/500    0.908G     13.25: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.83it/s]\n         0         0         0\n\n     epoch    memory      loss\n     5/500    0.914G     13.23: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.87it/s]\n         0         0         0\n\n     epoch    memory      loss\n     6/500    0.921G     13.33: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.62it/s]\n         0         0         0\n\n     epoch    memory      loss\n     7/500    0.927G      13.1: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.81it/s]\n         0         0         0\n\n     epoch    memory      loss\n     8/500    0.927G     13.08: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.62it/s]\n         0         0         0\n\n     epoch    memory      loss\n     9/500    0.927G     13.14: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 15.95it/s]\n         0         0         0\n\n     epoch    memory      loss\n    10/500    0.927G     13.19: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 17.00it/s]\n         0         0         0\n\n     epoch    memory      loss\n    11/500    0.927G     13.05: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.72it/s]\n         0         0         0\n\n     epoch    memory      loss\n    12/500    0.927G     13.04: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.60it/s]\n         0         0         0\n\n     epoch    memory      loss\n    13/500    0.927G     13.05: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.77it/s]\n         0         0         0\n\n     epoch    memory      loss\n    14/500    0.927G     12.89: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.93it/s]\n         0         0         0\n\n     epoch    memory      loss\n    15/500    0.927G     12.96: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.81it/s]\n         0         0         0\n\n     epoch    memory      loss\n    16/500    0.927G     12.94: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 15.95it/s]\n         0         0         0\n\n     epoch    memory      loss\n    17/500    0.927G     12.79: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.94it/s]\n         0         0         0\n\n     epoch    memory      loss\n    18/500    0.927G     12.85: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 14.17it/s]\n         0         0         0\n\n     epoch    memory      loss\n    19/500    0.927G     12.86: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.47it/s]\n         0         0         0\n\n     epoch    memory      loss\n    20/500    0.927G     12.74: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 13.28it/s]\n         0         0         0\n\n     epoch    memory      loss\n    21/500    0.912G     12.79: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 15.36it/s]\n         0         0         0\n\n     epoch    memory      loss\n    22/500    0.902G     12.75: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.67it/s]\n         0         0         0\n\n     epoch    memory      loss\n    23/500    0.902G     12.72: 100%|█████████████| 4/4 [00:03<00:00,  1.19it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.73it/s]\n         0         0         0\n\n     epoch    memory      loss\n    24/500    0.902G     12.62: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.85it/s]\n         0         0         0\n\n     epoch    memory      loss\n    25/500    0.902G     12.59: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 14.06it/s]\n         0         0         0\n\n     epoch    memory      loss\n    26/500    0.902G     12.55: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 17.09it/s]\n         0         0         0\n\n     epoch    memory      loss\n    27/500    0.902G     12.58: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 15.31it/s]\n         0         0         0\n\n     epoch    memory      loss\n    28/500    0.902G     12.46: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.61it/s]\n         0         0         0\n\n     epoch    memory      loss\n    29/500    0.902G     12.56: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.66it/s]\n         0         0         0\n\n     epoch    memory      loss\n    30/500    0.902G     12.53: 100%|█████████████| 4/4 [00:03<00:00,  1.19it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.06it/s]\n         0         0         0\n\n     epoch    memory      loss\n    31/500    0.908G     12.44: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 17.11it/s]\n         0         0         0\n\n     epoch    memory      loss\n    32/500    0.914G     12.62: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 15.33it/s]\n         0         0         0\n\n     epoch    memory      loss\n    33/500    0.921G      12.5: 100%|█████████████| 4/4 [00:03<00:00,  1.23it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 13.33it/s]\n         0         0         0\n\n     epoch    memory      loss\n    34/500    0.908G     12.39: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.83it/s]\n         0         0         0\n\n     epoch    memory      loss\n    35/500    0.906G     12.49: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.04it/s]\n         0         0         0\n\n     epoch    memory      loss\n    36/500    0.902G     12.36: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.14it/s]\n         0         0         0\n\n     epoch    memory      loss\n    37/500    0.902G     12.38: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 16.09it/s]\n         0         0         0\n\n     epoch    memory      loss\n    38/500    0.902G     12.39: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:00<00:00, 15.06it/s]\n         0         0         0\n\n     epoch    memory      loss\n    39/500    0.902G      12.3: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 12.92it/s]\n         0         0         0\n\n     epoch    memory      loss\n    40/500    0.902G      12.2: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 14.47it/s]\n         0         0         0\n\n     epoch    memory      loss\n    41/500    0.902G      12.2: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 14.10it/s]\n         0         0         0\n\n     epoch    memory      loss\n    42/500    0.904G     12.12: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 13.44it/s]\n         0         0         0\n\n     epoch    memory      loss\n    43/500    0.906G     12.13: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 12.50it/s]\n  1.84e-05  0.000279  1.69e-06\n\n     epoch    memory      loss\n    44/500    0.912G     12.07: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.84it/s]\n    0.0025   0.00937   0.00117\n\n     epoch    memory      loss\n    45/500    0.921G     12.13: 100%|█████████████| 4/4 [00:03<00:00,  1.23it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 12.02it/s]\n   0.00285   0.00889    0.0013\n\n     epoch    memory      loss\n    46/500    0.927G     12.12: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.69it/s]\n  0.000197   0.00528   0.00049\n\n     epoch    memory      loss\n    47/500    0.927G     12.13: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.63it/s]\n     0.592   0.00352  0.000723\n\n     epoch    memory      loss\n    48/500    0.927G     11.86: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.61it/s]\n  0.000707   0.00738  0.000925\n\n     epoch    memory      loss\n    49/500    0.927G     12.03: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.35it/s]\n   0.00252    0.0161  0.000311\n\n     epoch    memory      loss\n    50/500    0.927G     11.99: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.26it/s]\n  0.000495   0.00675  0.000354\n\n     epoch    memory      loss\n    51/500    0.927G      11.9: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.64it/s]\n     0.749   0.00156  0.000471\n\n     epoch    memory      loss\n    52/500    0.927G     11.85: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.40it/s]\n     0.283   0.00469  0.000477\n\n     epoch    memory      loss\n    53/500    0.927G     11.92: 100%|█████████████| 4/4 [00:03<00:00,  1.22it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.35it/s]\n      0.26   0.00626   0.00177\n\n     epoch    memory      loss\n    54/500    0.927G     11.97: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.08it/s]\n      0.31   0.00391  6.12e-05\n\n     epoch    memory      loss\n    55/500    0.927G     11.84: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.25it/s]\n     0.454   0.00822  0.000428\n\n     epoch    memory      loss\n    56/500    0.927G     11.97: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.01it/s]\n     0.367   0.00469  0.000249\n\n     epoch    memory      loss\n    57/500    0.927G     11.77: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.30it/s]\n  0.000654    0.0136  0.000139\n\n     epoch    memory      loss\n    58/500    0.927G     11.82: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.58it/s]\n  2.54e-05   0.00314  4.58e-06\n\n     epoch    memory      loss\n    59/500    0.927G     11.73: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.48it/s]\n  2.68e-05   0.00339  5.11e-06\n\n     epoch    memory      loss\n    60/500    0.925G     11.76: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.26it/s]\n  0.000979    0.0177  0.000287\n\n     epoch    memory      loss\n    61/500    0.921G     11.82: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.09it/s]\n   0.00076    0.0171  0.000235\n\n     epoch    memory      loss\n    62/500    0.921G     11.76: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.21it/s]\n  0.000298   0.00952  7.97e-05\n\n     epoch    memory      loss\n    63/500    0.921G     11.65: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.45it/s]\n  0.000268    0.0118  0.000123\n\n     epoch    memory      loss\n    64/500    0.921G     11.62: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.49it/s]\n      0.72   0.00352  0.000321\n\n     epoch    memory      loss\n    65/500    0.921G      11.6: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.55it/s]\n     0.652   0.00352  0.000509\n\n     epoch    memory      loss\n    66/500    0.921G     11.49: 100%|█████████████| 4/4 [00:03<00:00,  1.23it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.15it/s]\n     0.665   0.00352  0.000661\n\n     epoch    memory      loss\n    67/500    0.921G     11.42: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.87it/s]\n     0.623   0.00358   0.00127\n\n     epoch    memory      loss\n    68/500    0.921G     11.57: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.01it/s]\n     0.731   0.00352   0.00199\n\n     epoch    memory      loss\n    69/500    0.921G     11.46: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.93it/s]\n     0.805   0.00352   0.00157\n\n     epoch    memory      loss\n    70/500    0.921G      11.4: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.32it/s]\n     0.817   0.00352   0.00212\n\n     epoch    memory      loss\n    71/500    0.921G     11.45: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.74it/s]\n     0.466    0.0046  0.000263\n\n     epoch    memory      loss\n    72/500    0.921G      11.4: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.95it/s]\n     0.578    0.0111  0.000244\n\n     epoch    memory      loss\n    73/500    0.921G     11.37: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.75it/s]\n     0.732   0.00352   0.00216\n\n     epoch    memory      loss\n    74/500    0.921G     11.33: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.27it/s]\n     0.775   0.00352  0.000402\n\n     epoch    memory      loss\n    75/500    0.921G     11.19: 100%|█████████████| 4/4 [00:03<00:00,  1.17it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.23it/s]\n     0.678   0.00352   0.00094\n\n     epoch    memory      loss\n    76/500    0.912G     11.18: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.19it/s]\n      0.72   0.00352   0.00157\n\n     epoch    memory      loss\n    77/500    0.906G      11.1: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.09it/s]\n     0.739   0.00352   0.00141\n\n     epoch    memory      loss\n    78/500    0.904G     11.06: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.93it/s]\n      0.72   0.00352   0.00222\n\n     epoch    memory      loss\n    79/500    0.902G     11.25: 100%|█████████████| 4/4 [00:03<00:00,  1.20it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.84it/s]\n     0.666   0.00352   0.00224\n\n     epoch    memory      loss\n    80/500    0.902G     11.13: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.58it/s]\n     0.626   0.00352   0.00195\n\n     epoch    memory      loss\n    81/500    0.902G     11.03: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.89it/s]\n     0.485   0.00559   0.00188\n\n     epoch    memory      loss\n    82/500    0.902G     10.94: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 11.16it/s]\n     0.541   0.00352    0.0013\n\n     epoch    memory      loss\n    83/500    0.902G     11.01: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.86it/s]\n   0.00229    0.0409  0.000854\n\n     epoch    memory      loss\n    84/500    0.902G     10.98: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.13it/s]\n     0.327    0.0169  0.000906\n\n     epoch    memory      loss\n    85/500    0.902G     10.94: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.58it/s]\n     0.447    0.0135   0.00155\n\n     epoch    memory      loss\n    86/500    0.902G     10.91: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.51it/s]\n     0.522    0.0109   0.00127\n\n     epoch    memory      loss\n    87/500    0.902G     10.84: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.88it/s]\n     0.541    0.0124   0.00488\n\n     epoch    memory      loss\n    88/500    0.902G     10.67: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.74it/s]\n     0.504    0.0171   0.00383\n\n     epoch    memory      loss\n    89/500    0.902G     10.66: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.52it/s]\n     0.619    0.0111   0.00406\n\n     epoch    memory      loss\n    90/500    0.902G     10.62: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.41it/s]\n     0.388    0.0243    0.0036\n\n     epoch    memory      loss\n    91/500    0.902G     10.64: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n     0.461    0.0243   0.00403\n\n     epoch    memory      loss\n    92/500    0.902G     10.68: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.69it/s]\n     0.492    0.0138   0.00451\n\n     epoch    memory      loss\n    93/500    0.902G     10.51: 100%|█████████████| 4/4 [00:03<00:00,  1.26it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.54it/s]\n     0.437    0.0272   0.00412\n\n     epoch    memory      loss\n    94/500    0.902G     10.46: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.94it/s]\n     0.578    0.0184   0.00658\n\n     epoch    memory      loss\n    95/500    0.902G     10.52: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.43it/s]\n     0.374    0.0296    0.0048\n\n     epoch    memory      loss\n    96/500    0.902G     10.58: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.62it/s]\n     0.178    0.0571   0.00474\n\n     epoch    memory      loss\n    97/500    0.902G     10.47: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.47it/s]\n     0.446    0.0117   0.00433\n\n     epoch    memory      loss\n    98/500    0.902G     10.28: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.50it/s]\n     0.483    0.0164   0.00587\n\n     epoch    memory      loss\n    99/500    0.902G      10.5: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.69it/s]\n     0.353    0.0276   0.00647\n\n     epoch    memory      loss\n   100/500    0.902G     10.44: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.57it/s]\n     0.482    0.0134   0.00379\n\n     epoch    memory      loss\n   101/500    0.902G     10.34: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.26it/s]\n      0.41    0.0316    0.0056\n\n     epoch    memory      loss\n   102/500    0.902G     10.23: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.20it/s]\n     0.484    0.0409   0.00741\n\n     epoch    memory      loss\n   103/500    0.902G     10.39: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.91it/s]\n     0.495    0.0266   0.00487\n\n     epoch    memory      loss\n   104/500    0.902G      10.2: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.13it/s]\n     0.413    0.0258   0.00256\n\n     epoch    memory      loss\n   105/500    0.902G     10.22: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.19it/s]\n     0.324    0.0317   0.00403\n\n     epoch    memory      loss\n   106/500    0.902G     10.19: 100%|█████████████| 4/4 [00:03<00:00,  1.23it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.85it/s]\n     0.452    0.0267   0.00461\n\n     epoch    memory      loss\n   107/500    0.902G     10.11: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.57it/s]\n     0.501    0.0234   0.00291\n\n     epoch    memory      loss\n   108/500    0.902G     10.15: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.29it/s]\n     0.455    0.0301   0.00635\n\n     epoch    memory      loss\n   109/500    0.902G     9.938: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.49it/s]\n     0.461    0.0272   0.00824\n\n     epoch    memory      loss\n   110/500    0.902G     10.04: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.67it/s]\n      0.52    0.0349    0.0106\n\n     epoch    memory      loss\n   111/500    0.902G     9.886: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.431    0.0433   0.00765\n\n     epoch    memory      loss\n   112/500    0.902G     10.06: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.401    0.0414   0.00893\n\n     epoch    memory      loss\n   113/500    0.902G     9.817: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.35it/s]\n     0.518    0.0476    0.0133\n\n     epoch    memory      loss\n   114/500    0.902G     9.948: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.70it/s]\n     0.579    0.0403    0.0118\n\n     epoch    memory      loss\n   115/500    0.902G     9.771: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.60it/s]\n     0.517     0.035    0.0103\n\n     epoch    memory      loss\n   116/500    0.902G     9.795: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.00it/s]\n     0.545    0.0385     0.011\n\n     epoch    memory      loss\n   117/500    0.902G     9.886: 100%|█████████████| 4/4 [00:03<00:00,  1.24it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.41it/s]\n     0.648    0.0334    0.0105\n\n     epoch    memory      loss\n   118/500    0.902G     9.751: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n      0.64    0.0347   0.00623\n\n     epoch    memory      loss\n   119/500    0.902G      9.71: 100%|█████████████| 4/4 [00:03<00:00,  1.31it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.26it/s]\n     0.706    0.0243    0.0112\n\n     epoch    memory      loss\n   120/500    0.902G     9.672: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.16it/s]\n     0.491    0.0467    0.0115\n\n     epoch    memory      loss\n   121/500    0.902G     9.688: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.47it/s]\n       0.6    0.0352   0.00914\n\n     epoch    memory      loss\n   122/500    0.902G     9.524: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.57it/s]\n     0.548    0.0518    0.0125\n\n     epoch    memory      loss\n   123/500    0.902G     9.532: 100%|█████████████| 4/4 [00:03<00:00,  1.24it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.90it/s]\n     0.583    0.0553    0.0103\n\n     epoch    memory      loss\n   124/500    0.902G     9.494: 100%|█████████████| 4/4 [00:03<00:00,  1.25it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.34it/s]\n     0.607    0.0438    0.0193\n\n     epoch    memory      loss\n   125/500    0.902G     9.557: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.75it/s]\n     0.604    0.0308     0.013\n\n     epoch    memory      loss\n   126/500     3.21G     9.582: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.90it/s]\n     0.577    0.0503    0.0226\n\n     epoch    memory      loss\n   127/500     3.12G     9.545: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.58it/s]\n     0.563    0.0492    0.0204\n\n     epoch    memory      loss\n   128/500     3.26G     9.417: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.604    0.0517    0.0225\n\n     epoch    memory      loss\n   129/500     3.06G     9.357: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.41it/s]\n     0.614    0.0568    0.0175\n\n     epoch    memory      loss\n   130/500     3.18G     9.227: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.12it/s]\n     0.666    0.0426    0.0152\n\n     epoch    memory      loss\n   131/500     3.23G     9.194: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.07it/s]\n     0.642    0.0371    0.0187\n\n     epoch    memory      loss\n   132/500     3.33G     9.276: 100%|█████████████| 4/4 [00:02<00:00,  1.51it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.51it/s]\n     0.663    0.0465     0.023\n\n     epoch    memory      loss\n   133/500     2.71G     9.248: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.06it/s]\n      0.57    0.0587    0.0178\n\n     epoch    memory      loss\n   134/500     2.68G     9.233: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.53it/s]\n     0.598     0.037    0.0143\n\n     epoch    memory      loss\n   135/500     3.03G     9.285: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.43it/s]\n     0.543      0.05    0.0145\n\n     epoch    memory      loss\n   136/500     3.06G     9.225: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.07it/s]\n     0.627    0.0377    0.0146\n\n     epoch    memory      loss\n   137/500     3.12G      9.01: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.03it/s]\n     0.643    0.0455    0.0197\n\n     epoch    memory      loss\n   138/500     3.25G     9.232: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.32it/s]\n     0.637    0.0502    0.0213\n\n     epoch    memory      loss\n   139/500     3.12G     9.111: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.65it/s]\n     0.667    0.0351     0.025\n\n     epoch    memory      loss\n   140/500      3.3G     9.204: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.651    0.0417     0.033\n\n     epoch    memory      loss\n   141/500     3.23G     9.056: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.46it/s]\n      0.64    0.0487    0.0165\n\n     epoch    memory      loss\n   142/500     3.28G     8.914: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.84it/s]\n     0.667     0.047    0.0174\n\n     epoch    memory      loss\n   143/500     3.18G     8.921: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.01it/s]\n      0.64    0.0608     0.023\n\n     epoch    memory      loss\n   144/500      3.1G     8.923: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.646    0.0531    0.0251\n\n     epoch    memory      loss\n   145/500     3.21G     8.872: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.26it/s]\n     0.646    0.0531    0.0258\n\n     epoch    memory      loss\n   146/500     3.03G     8.967: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.29it/s]\n     0.648     0.067    0.0271\n\n     epoch    memory      loss\n   147/500     2.69G     8.949: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.20it/s]\n      0.62     0.078    0.0281\n\n     epoch    memory      loss\n   148/500     3.09G     8.919: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.44it/s]\n     0.651    0.0759    0.0247\n\n     epoch    memory      loss\n   149/500     3.24G     8.954: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.95it/s]\n     0.704    0.0707    0.0282\n\n     epoch    memory      loss\n   150/500     2.68G     8.987: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.17it/s]\n     0.649    0.0741     0.027\n\n     epoch    memory      loss\n   151/500     3.27G     8.882: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.31it/s]\n     0.657    0.0706    0.0334\n\n     epoch    memory      loss\n   152/500     3.19G     8.891: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.08it/s]\n     0.623    0.0723    0.0283\n\n     epoch    memory      loss\n   153/500     3.02G     8.678: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.588     0.063    0.0308\n\n     epoch    memory      loss\n   154/500     2.69G     8.864: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.36it/s]\n     0.688    0.0822    0.0371\n\n     epoch    memory      loss\n   155/500     3.35G     8.924: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.563    0.0785    0.0376\n\n     epoch    memory      loss\n   156/500     3.17G     8.702: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.86it/s]\n     0.614    0.0752    0.0403\n\n     epoch    memory      loss\n   157/500     3.24G     8.648: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.609    0.0665     0.038\n\n     epoch    memory      loss\n   158/500     3.11G     8.593: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.21it/s]\n     0.662    0.0857    0.0377\n\n     epoch    memory      loss\n   159/500     3.37G     8.682: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.20it/s]\n     0.673    0.0859    0.0419\n\n     epoch    memory      loss\n   160/500     3.37G      8.53: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.20it/s]\n     0.616    0.0848    0.0423\n\n     epoch    memory      loss\n   161/500     3.01G     8.731: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.55it/s]\n     0.655    0.0873    0.0364\n\n     epoch    memory      loss\n   162/500     3.07G     8.536: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.28it/s]\n     0.679     0.062    0.0309\n\n     epoch    memory      loss\n   163/500     3.23G     8.689: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.27it/s]\n     0.679     0.075    0.0381\n\n     epoch    memory      loss\n   164/500     3.42G     8.694: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.00it/s]\n     0.675    0.0706     0.034\n\n     epoch    memory      loss\n   165/500      3.2G     8.472: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n     0.672    0.0812    0.0392\n\n     epoch    memory      loss\n   166/500     3.33G       8.4: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.702    0.0762    0.0432\n\n     epoch    memory      loss\n   167/500     3.22G      8.43: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.32it/s]\n      0.64     0.093    0.0375\n\n     epoch    memory      loss\n   168/500     2.67G     8.618: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.07it/s]\n     0.652    0.0903    0.0378\n\n     epoch    memory      loss\n   169/500     3.01G     8.437: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.01it/s]\n     0.727    0.0613    0.0345\n\n     epoch    memory      loss\n   170/500     3.07G     8.395: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.37it/s]\n     0.672    0.0961    0.0426\n\n     epoch    memory      loss\n   171/500     3.04G     8.359: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.58it/s]\n      0.61       0.1    0.0478\n\n     epoch    memory      loss\n   172/500     3.36G     8.282: 100%|█████████████| 4/4 [00:02<00:00,  1.52it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.29it/s]\n     0.662    0.0881    0.0445\n\n     epoch    memory      loss\n   173/500      3.2G     8.307: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.25it/s]\n     0.708    0.0846     0.049\n\n     epoch    memory      loss\n   174/500     3.05G     8.233: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.36it/s]\n     0.671    0.0937     0.049\n\n     epoch    memory      loss\n   175/500     3.19G     8.324: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.11it/s]\n     0.676    0.0945    0.0527\n\n     epoch    memory      loss\n   176/500      3.1G     8.296: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.53it/s]\n     0.633       0.1     0.052\n\n     epoch    memory      loss\n   177/500     3.29G      8.12: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.40it/s]\n     0.565    0.0862    0.0459\n\n     epoch    memory      loss\n   178/500     3.09G     8.204: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.44it/s]\n     0.579    0.0936    0.0418\n\n     epoch    memory      loss\n   179/500     3.24G      8.38: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.46it/s]\n     0.644    0.0929    0.0437\n\n     epoch    memory      loss\n   180/500     2.68G     8.203: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.31it/s]\n     0.637    0.0915    0.0459\n\n     epoch    memory      loss\n   181/500     3.27G     8.173: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.06it/s]\n     0.619    0.0981    0.0453\n\n     epoch    memory      loss\n   182/500     3.09G     8.243: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.24it/s]\n       0.6    0.0993    0.0464\n\n     epoch    memory      loss\n   183/500     3.02G     8.194: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.20it/s]\n     0.523     0.136     0.059\n\n     epoch    memory      loss\n   184/500      3.2G     8.018: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.27it/s]\n     0.514     0.126    0.0544\n\n     epoch    memory      loss\n   185/500     3.01G     8.135: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.42it/s]\n     0.605     0.107    0.0553\n\n     epoch    memory      loss\n   186/500     3.33G      8.11: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.26it/s]\n     0.632     0.105    0.0526\n\n     epoch    memory      loss\n   187/500     2.71G     8.228: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.52it/s]\n     0.661      0.11    0.0548\n\n     epoch    memory      loss\n   188/500     2.71G     8.172: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.68it/s]\n       0.7    0.0923    0.0531\n\n     epoch    memory      loss\n   189/500     3.15G     8.012: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.53it/s]\n     0.662    0.0912    0.0511\n\n     epoch    memory      loss\n   190/500      3.1G     7.973: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.41it/s]\n     0.653    0.0912    0.0467\n\n     epoch    memory      loss\n   191/500     3.08G     7.913: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.52it/s]\n     0.627     0.115      0.06\n\n     epoch    memory      loss\n   192/500     2.71G     7.974: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.23it/s]\n     0.563     0.138    0.0687\n\n     epoch    memory      loss\n   193/500     2.69G     7.887: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.34it/s]\n     0.512      0.13    0.0645\n\n     epoch    memory      loss\n   194/500     3.24G     7.917: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.94it/s]\n     0.508     0.138    0.0591\n\n     epoch    memory      loss\n   195/500     3.02G     7.955: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.97it/s]\n     0.538     0.164    0.0599\n\n     epoch    memory      loss\n   196/500      2.7G      7.86: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.39it/s]\n     0.553     0.128    0.0521\n\n     epoch    memory      loss\n   197/500     3.22G     7.749: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.24it/s]\n     0.583     0.125    0.0556\n\n     epoch    memory      loss\n   198/500     2.72G     7.878: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.26it/s]\n     0.604     0.129    0.0682\n\n     epoch    memory      loss\n   199/500      3.2G     7.923: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.22it/s]\n     0.572     0.165    0.0811\n\n     epoch    memory      loss\n   200/500     3.16G     7.968: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.18it/s]\n     0.563     0.164    0.0874\n\n     epoch    memory      loss\n   201/500     3.05G     7.725: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.93it/s]\n     0.481      0.15    0.0755\n\n     epoch    memory      loss\n   202/500     3.34G     7.766: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n     0.456     0.178    0.0776\n\n     epoch    memory      loss\n   203/500     3.34G     7.731: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n     0.455     0.167    0.0738\n\n     epoch    memory      loss\n   204/500     3.02G     7.752: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.26it/s]\n     0.494      0.16    0.0781\n\n     epoch    memory      loss\n   205/500     3.44G     7.625: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.41it/s]\n     0.427     0.202    0.0883\n\n     epoch    memory      loss\n   206/500      2.7G     7.675: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.66it/s]\n     0.582     0.145    0.0749\n\n     epoch    memory      loss\n   207/500     3.13G     7.716: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.85it/s]\n     0.586     0.163    0.0757\n\n     epoch    memory      loss\n   208/500     3.12G     7.673: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.07it/s]\n     0.567     0.141    0.0639\n\n     epoch    memory      loss\n   209/500     3.34G     7.531: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n     0.471     0.192     0.083\n\n     epoch    memory      loss\n   210/500     3.22G     7.525: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n     0.443     0.179    0.0903\n\n     epoch    memory      loss\n   211/500     3.03G     7.515: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.409     0.205    0.0995\n\n     epoch    memory      loss\n   212/500     2.71G     7.516: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.08it/s]\n     0.423     0.202     0.101\n\n     epoch    memory      loss\n   213/500        3G     7.674: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.95it/s]\n     0.493     0.151    0.0865\n\n     epoch    memory      loss\n   214/500     3.24G     7.663: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n      0.44     0.196     0.097\n\n     epoch    memory      loss\n   215/500     3.03G     7.498: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n      0.59     0.167     0.102\n\n     epoch    memory      loss\n   216/500     3.16G     7.541: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.23it/s]\n     0.508      0.19    0.0985\n\n     epoch    memory      loss\n   217/500     3.04G     7.439: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.567     0.184    0.0992\n\n     epoch    memory      loss\n   218/500     2.71G     7.557: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.07it/s]\n     0.543     0.201     0.106\n\n     epoch    memory      loss\n   219/500     3.14G     7.342: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.33it/s]\n     0.574     0.191    0.0963\n\n     epoch    memory      loss\n   220/500     3.09G     7.276: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.492     0.216     0.106\n\n     epoch    memory      loss\n   221/500     3.04G     7.495: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.23it/s]\n      0.37     0.194     0.106\n\n     epoch    memory      loss\n   222/500     3.27G     7.226: 100%|█████████████| 4/4 [00:03<00:00,  1.27it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.15it/s]\n     0.427     0.206     0.117\n\n     epoch    memory      loss\n   223/500     3.55G     7.488: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.15it/s]\n     0.508     0.197     0.114\n\n     epoch    memory      loss\n   224/500     3.13G     7.373: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.01it/s]\n     0.391     0.212     0.109\n\n     epoch    memory      loss\n   225/500     3.03G     7.339: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.11it/s]\n     0.478     0.223      0.12\n\n     epoch    memory      loss\n   226/500     3.14G     7.233: 100%|█████████████| 4/4 [00:03<00:00,  1.24it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.465     0.211     0.108\n\n     epoch    memory      loss\n   227/500     3.07G     7.393: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.75it/s]\n     0.483     0.207     0.105\n\n     epoch    memory      loss\n   228/500     3.36G     7.204: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.01it/s]\n     0.593     0.165     0.112\n\n     epoch    memory      loss\n   229/500     2.99G     7.112: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.93it/s]\n     0.508     0.232     0.129\n\n     epoch    memory      loss\n   230/500     3.65G     7.402: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.525     0.238     0.122\n\n     epoch    memory      loss\n   231/500      3.3G     7.271: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.21it/s]\n     0.541     0.194    0.0997\n\n     epoch    memory      loss\n   232/500     3.34G     7.166: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n     0.449     0.203      0.12\n\n     epoch    memory      loss\n   233/500     3.32G     7.156: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.01it/s]\n      0.46      0.24     0.133\n\n     epoch    memory      loss\n   234/500     3.25G     7.233: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.23it/s]\n     0.543      0.23     0.141\n\n     epoch    memory      loss\n   235/500     3.18G     7.044: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.98it/s]\n     0.534     0.236     0.137\n\n     epoch    memory      loss\n   236/500     3.08G     7.223: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.76it/s]\n     0.534     0.239     0.127\n\n     epoch    memory      loss\n   237/500     2.68G     7.189: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.18it/s]\n      0.59     0.219     0.138\n\n     epoch    memory      loss\n   238/500     3.05G     7.151: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.94it/s]\n     0.554     0.213     0.134\n\n     epoch    memory      loss\n   239/500     3.03G     6.984: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.423     0.225     0.134\n\n     epoch    memory      loss\n   240/500     3.14G     7.186: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.437      0.22     0.116\n\n     epoch    memory      loss\n   241/500     3.16G     7.021: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n      0.38     0.239     0.111\n\n     epoch    memory      loss\n   242/500     3.55G     7.025: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.69it/s]\n     0.451     0.272     0.134\n\n     epoch    memory      loss\n   243/500     3.03G     6.874: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.457      0.28     0.144\n\n     epoch    memory      loss\n   244/500     3.24G     6.976: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.24it/s]\n     0.493      0.27     0.171\n\n     epoch    memory      loss\n   245/500     2.98G     7.074: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.11it/s]\n     0.488     0.266     0.164\n\n     epoch    memory      loss\n   246/500      3.2G     6.896: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.481     0.258     0.159\n\n     epoch    memory      loss\n   247/500     3.08G     6.975: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.59it/s]\n     0.483     0.257     0.165\n\n     epoch    memory      loss\n   248/500      3.4G     6.888: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.99it/s]\n     0.517     0.254     0.165\n\n     epoch    memory      loss\n   249/500     3.29G     6.663: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.18it/s]\n     0.499     0.269      0.16\n\n     epoch    memory      loss\n   250/500     3.03G     6.936: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n     0.433     0.267     0.157\n\n     epoch    memory      loss\n   251/500     3.13G     6.956: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n      0.53     0.309     0.173\n\n     epoch    memory      loss\n   252/500     3.16G     6.743: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.503     0.317     0.182\n\n     epoch    memory      loss\n   253/500     3.12G     6.734: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n     0.492     0.329     0.182\n\n     epoch    memory      loss\n   254/500     3.18G     6.776: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.05it/s]\n     0.522     0.276      0.17\n\n     epoch    memory      loss\n   255/500     3.24G     6.842: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.07it/s]\n     0.594     0.279     0.179\n\n     epoch    memory      loss\n   256/500     3.17G     6.813: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.12it/s]\n     0.537      0.29     0.171\n\n     epoch    memory      loss\n   257/500     3.11G     6.717: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.563     0.299     0.191\n\n     epoch    memory      loss\n   258/500     3.02G     6.573: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.529     0.312     0.191\n\n     epoch    memory      loss\n   259/500      3.2G     6.722: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.512      0.32     0.197\n\n     epoch    memory      loss\n   260/500     2.68G     6.744: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.76it/s]\n     0.559     0.318     0.197\n\n     epoch    memory      loss\n   261/500     3.08G     6.689: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.65it/s]\n     0.474     0.369     0.207\n\n     epoch    memory      loss\n   262/500     3.21G     6.703: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.54it/s]\n     0.471     0.348     0.209\n\n     epoch    memory      loss\n   263/500     3.15G      6.62: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.519     0.321     0.211\n\n     epoch    memory      loss\n   264/500      3.2G     6.464: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.10it/s]\n      0.62     0.281      0.21\n\n     epoch    memory      loss\n   265/500     3.05G     6.506: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n     0.498     0.378     0.224\n\n     epoch    memory      loss\n   266/500     3.34G     6.562: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n     0.517     0.364     0.209\n\n     epoch    memory      loss\n   267/500     3.15G     6.571: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.69it/s]\n     0.459     0.384     0.219\n\n     epoch    memory      loss\n   268/500     3.11G     6.613: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.08it/s]\n     0.549     0.312     0.206\n\n     epoch    memory      loss\n   269/500     3.37G     6.541: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.15it/s]\n     0.573     0.342     0.204\n\n     epoch    memory      loss\n   270/500     3.39G     6.547: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.94it/s]\n     0.604     0.313     0.206\n\n     epoch    memory      loss\n   271/500     3.26G     6.463: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.98it/s]\n     0.555     0.356     0.222\n\n     epoch    memory      loss\n   272/500     3.21G     6.616: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n     0.597     0.354     0.229\n\n     epoch    memory      loss\n   273/500     3.28G      6.31: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.85it/s]\n     0.524     0.325     0.204\n\n     epoch    memory      loss\n   274/500     3.17G     6.401: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.08it/s]\n     0.604     0.365     0.241\n\n     epoch    memory      loss\n   275/500     3.26G     6.278: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.16it/s]\n     0.561      0.38     0.245\n\n     epoch    memory      loss\n   276/500     3.26G     6.445: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n     0.555     0.388     0.248\n\n     epoch    memory      loss\n   277/500     3.17G     6.435: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.98it/s]\n     0.608     0.355     0.241\n\n     epoch    memory      loss\n   278/500     3.18G     6.406: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.15it/s]\n     0.691     0.328     0.246\n\n     epoch    memory      loss\n   279/500     3.33G     6.376: 100%|█████████████| 4/4 [00:02<00:00,  1.53it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.672     0.357     0.259\n\n     epoch    memory      loss\n   280/500     3.22G     6.236: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.74it/s]\n     0.557     0.384     0.246\n\n     epoch    memory      loss\n   281/500     3.24G     6.344: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.03it/s]\n     0.589     0.365     0.236\n\n     epoch    memory      loss\n   282/500     3.05G     6.207: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.11it/s]\n     0.587     0.371     0.245\n\n     epoch    memory      loss\n   283/500     3.04G     6.336: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.67it/s]\n     0.541     0.382     0.242\n\n     epoch    memory      loss\n   284/500     4.01G     6.214: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.55it/s]\n     0.651     0.394     0.271\n\n     epoch    memory      loss\n   285/500     3.21G     6.242: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.577     0.425      0.27\n\n     epoch    memory      loss\n   286/500     3.31G     6.222: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.48it/s]\n     0.563     0.427     0.247\n\n     epoch    memory      loss\n   287/500     3.33G     6.217: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.82it/s]\n     0.629     0.367     0.241\n\n     epoch    memory      loss\n   288/500     3.02G     6.098: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.633     0.379     0.256\n\n     epoch    memory      loss\n   289/500     3.08G     6.228: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.555     0.399     0.259\n\n     epoch    memory      loss\n   290/500     3.21G     6.103: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.549     0.439     0.273\n\n     epoch    memory      loss\n   291/500     3.09G      6.02: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.84it/s]\n     0.625     0.413     0.264\n\n     epoch    memory      loss\n   292/500     3.13G     6.163: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.72it/s]\n     0.594     0.414      0.28\n\n     epoch    memory      loss\n   293/500     3.26G     6.076: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.678     0.394     0.284\n\n     epoch    memory      loss\n   294/500     3.17G     6.238: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.85it/s]\n     0.733       0.4     0.315\n\n     epoch    memory      loss\n   295/500     3.22G     5.891: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.52it/s]\n     0.747     0.397     0.311\n\n     epoch    memory      loss\n   296/500     3.56G     6.019: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.638      0.41     0.294\n\n     epoch    memory      loss\n   297/500     3.19G     6.056: 100%|█████████████| 4/4 [00:03<00:00,  1.28it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.615     0.431     0.295\n\n     epoch    memory      loss\n   298/500     3.05G     6.004: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.585     0.452     0.312\n\n     epoch    memory      loss\n   299/500     3.51G     5.869: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n     0.678     0.406      0.31\n\n     epoch    memory      loss\n   300/500      3.1G     5.976: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.656     0.449      0.32\n\n     epoch    memory      loss\n   301/500     2.99G     6.001: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.702     0.399     0.315\n\n     epoch    memory      loss\n   302/500     3.27G     5.984: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.97it/s]\n     0.661     0.417     0.313\n\n     epoch    memory      loss\n   303/500     3.02G      6.01: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.613     0.433     0.314\n\n     epoch    memory      loss\n   304/500      3.1G     5.844: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.21it/s]\n     0.647     0.392     0.304\n\n     epoch    memory      loss\n   305/500      2.7G      5.95: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.675     0.405     0.309\n\n     epoch    memory      loss\n   306/500     3.16G     5.758: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.12it/s]\n     0.707     0.404     0.304\n\n     epoch    memory      loss\n   307/500     3.24G     5.829: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.635     0.447     0.313\n\n     epoch    memory      loss\n   308/500     3.24G     5.833: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.70it/s]\n     0.713     0.441      0.34\n\n     epoch    memory      loss\n   309/500     2.71G         6: 100%|█████████████| 4/4 [00:03<00:00,  1.32it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.70it/s]\n     0.677     0.452     0.335\n\n     epoch    memory      loss\n   310/500     3.17G     5.572: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.712     0.455     0.347\n\n     epoch    memory      loss\n   311/500     3.32G     5.632: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.79it/s]\n     0.742     0.453     0.349\n\n     epoch    memory      loss\n   312/500     3.04G     5.739: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.752     0.442     0.342\n\n     epoch    memory      loss\n   313/500     3.02G     5.797: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.75it/s]\n     0.675     0.499     0.343\n\n     epoch    memory      loss\n   314/500     3.11G     5.816: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.713     0.457     0.335\n\n     epoch    memory      loss\n   315/500     2.68G     5.874: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.05it/s]\n     0.699     0.453     0.326\n\n     epoch    memory      loss\n   316/500     3.23G     5.677: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.675     0.473     0.327\n\n     epoch    memory      loss\n   317/500     3.18G     5.747: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.725     0.449     0.337\n\n     epoch    memory      loss\n   318/500     3.33G     5.648: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.685     0.457     0.331\n\n     epoch    memory      loss\n   319/500     3.01G     5.746: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n      0.75     0.449     0.347\n\n     epoch    memory      loss\n   320/500     3.12G     5.705: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.759     0.429     0.351\n\n     epoch    memory      loss\n   321/500     3.04G      5.88: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.03it/s]\n     0.727     0.459     0.361\n\n     epoch    memory      loss\n   322/500     3.11G     5.471: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.744     0.428     0.352\n\n     epoch    memory      loss\n   323/500      3.1G     5.687: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n     0.694     0.426     0.334\n\n     epoch    memory      loss\n   324/500     3.41G     5.718: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.664     0.465     0.348\n\n     epoch    memory      loss\n   325/500     3.22G     5.601: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.681     0.463     0.354\n\n     epoch    memory      loss\n   326/500     3.14G     5.818: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.72it/s]\n     0.688     0.468     0.351\n\n     epoch    memory      loss\n   327/500      3.1G     5.521: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.673     0.493     0.373\n\n     epoch    memory      loss\n   328/500     3.15G     5.693: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.21it/s]\n     0.653     0.492      0.37\n\n     epoch    memory      loss\n   329/500      2.7G     5.601: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.628     0.513     0.355\n\n     epoch    memory      loss\n   330/500     2.67G     5.532: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.665     0.519     0.353\n\n     epoch    memory      loss\n   331/500     3.38G     5.536: 100%|█████████████| 4/4 [00:02<00:00,  1.51it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.14it/s]\n     0.639     0.527     0.355\n\n     epoch    memory      loss\n   332/500     3.06G     5.633: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.89it/s]\n     0.643     0.528     0.352\n\n     epoch    memory      loss\n   333/500     3.11G     5.559: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n       0.7     0.499     0.359\n\n     epoch    memory      loss\n   334/500     3.33G     5.562: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.09it/s]\n       0.6     0.505     0.365\n\n     epoch    memory      loss\n   335/500     3.11G     5.456: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.706     0.463     0.392\n\n     epoch    memory      loss\n   336/500     3.12G     5.495: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.656     0.528     0.401\n\n     epoch    memory      loss\n   337/500     3.06G     5.486: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.95it/s]\n     0.707     0.533     0.407\n\n     epoch    memory      loss\n   338/500     3.07G     5.343: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.717     0.496     0.394\n\n     epoch    memory      loss\n   339/500     3.06G     5.472: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.726     0.507     0.384\n\n     epoch    memory      loss\n   340/500     3.14G     5.504: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.65it/s]\n     0.728     0.493     0.383\n\n     epoch    memory      loss\n   341/500     3.08G     5.506: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.45it/s]\n     0.667     0.544     0.393\n\n     epoch    memory      loss\n   342/500     3.21G      5.45: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.57it/s]\n     0.673     0.537     0.405\n\n     epoch    memory      loss\n   343/500     3.45G     5.337: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.697     0.536     0.402\n\n     epoch    memory      loss\n   344/500      3.1G     5.487: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.715     0.533      0.41\n\n     epoch    memory      loss\n   345/500     3.31G     5.427: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.00it/s]\n     0.682     0.537     0.412\n\n     epoch    memory      loss\n   346/500     3.18G     5.405: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.72it/s]\n     0.656      0.53     0.403\n\n     epoch    memory      loss\n   347/500     3.05G     5.427: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.15it/s]\n     0.712     0.552     0.418\n\n     epoch    memory      loss\n   348/500     3.31G     5.556: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.74it/s]\n     0.749     0.525     0.413\n\n     epoch    memory      loss\n   349/500     3.22G     5.475: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n      0.76     0.514     0.411\n\n     epoch    memory      loss\n   350/500     3.31G     5.326: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.731     0.541     0.405\n\n     epoch    memory      loss\n   351/500     3.25G     5.253: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.11it/s]\n     0.732     0.549     0.415\n\n     epoch    memory      loss\n   352/500     3.31G     5.274: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.93it/s]\n      0.69     0.563      0.41\n\n     epoch    memory      loss\n   353/500     2.68G     5.175: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.742     0.534     0.413\n\n     epoch    memory      loss\n   354/500     3.18G     5.304: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.97it/s]\n     0.734     0.523     0.407\n\n     epoch    memory      loss\n   355/500     3.14G     5.341: 100%|█████████████| 4/4 [00:03<00:00,  1.30it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n     0.744     0.532     0.433\n\n     epoch    memory      loss\n   356/500     3.07G     5.413: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.764     0.526     0.439\n\n     epoch    memory      loss\n   357/500     3.32G     4.967: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.03it/s]\n     0.759     0.544     0.437\n\n     epoch    memory      loss\n   358/500     3.31G     5.308: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n     0.763     0.534     0.442\n\n     epoch    memory      loss\n   359/500      3.2G     5.229: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.73it/s]\n     0.738     0.544     0.446\n\n     epoch    memory      loss\n   360/500     3.05G     5.248: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.12it/s]\n     0.739     0.554     0.454\n\n     epoch    memory      loss\n   361/500     3.15G      5.24: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.95it/s]\n     0.773     0.557     0.451\n\n     epoch    memory      loss\n   362/500     3.07G     5.283: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.99it/s]\n      0.76     0.535     0.445\n\n     epoch    memory      loss\n   363/500     3.29G     5.141: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.99it/s]\n     0.757     0.549     0.452\n\n     epoch    memory      loss\n   364/500     3.13G     5.105: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.67it/s]\n     0.771     0.489     0.425\n\n     epoch    memory      loss\n   365/500     3.13G     5.272: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.98it/s]\n     0.706     0.552     0.445\n\n     epoch    memory      loss\n   366/500      3.4G     5.173: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.13it/s]\n     0.743     0.562     0.456\n\n     epoch    memory      loss\n   367/500     2.71G     5.113: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.79it/s]\n     0.749     0.556     0.449\n\n     epoch    memory      loss\n   368/500     3.17G     5.215: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n     0.814      0.52     0.447\n\n     epoch    memory      loss\n   369/500     3.46G     5.331: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.73it/s]\n     0.748     0.561     0.454\n\n     epoch    memory      loss\n   370/500     3.16G     5.098: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.98it/s]\n     0.782     0.538     0.451\n\n     epoch    memory      loss\n   371/500     3.22G      5.27: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n      0.79     0.551      0.46\n\n     epoch    memory      loss\n   372/500     2.67G      5.23: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.743     0.592     0.467\n\n     epoch    memory      loss\n   373/500     3.47G     4.967: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n     0.781     0.566     0.472\n\n     epoch    memory      loss\n   374/500     3.12G     5.135: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.44it/s]\n     0.793     0.563     0.476\n\n     epoch    memory      loss\n   375/500     3.02G     5.249: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.779     0.568     0.465\n\n     epoch    memory      loss\n   376/500     3.18G     5.139: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.97it/s]\n     0.758     0.583     0.471\n\n     epoch    memory      loss\n   377/500     3.54G     5.228: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.85it/s]\n      0.78     0.601     0.498\n\n     epoch    memory      loss\n   378/500     3.33G     5.088: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.04it/s]\n     0.811     0.583     0.488\n\n     epoch    memory      loss\n   379/500     3.18G     5.044: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n     0.757       0.6      0.48\n\n     epoch    memory      loss\n   380/500     3.28G     5.187: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.781     0.573     0.458\n\n     epoch    memory      loss\n   381/500     3.08G     5.014: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.10it/s]\n     0.762     0.573     0.457\n\n     epoch    memory      loss\n   382/500     3.26G     5.122: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n     0.784     0.553     0.457\n\n     epoch    memory      loss\n   383/500     3.52G     4.992: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.94it/s]\n     0.735     0.582      0.46\n\n     epoch    memory      loss\n   384/500     3.07G     5.278: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.739     0.589     0.459\n\n     epoch    memory      loss\n   385/500     3.28G     5.002: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.743      0.56     0.472\n\n     epoch    memory      loss\n   386/500     3.12G     4.906: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.79it/s]\n     0.755     0.573     0.478\n\n     epoch    memory      loss\n   387/500     3.01G     4.968: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.761     0.593     0.479\n\n     epoch    memory      loss\n   388/500     3.09G     4.932: 100%|█████████████| 4/4 [00:02<00:00,  1.34it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.775     0.582     0.492\n\n     epoch    memory      loss\n   389/500     3.19G     5.099: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.762     0.593     0.489\n\n     epoch    memory      loss\n   390/500     3.07G     5.001: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.819     0.576     0.495\n\n     epoch    memory      loss\n   391/500     2.66G     4.957: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.839     0.557     0.494\n\n     epoch    memory      loss\n   392/500     3.12G     4.973: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.785     0.566     0.489\n\n     epoch    memory      loss\n   393/500     3.08G     4.955: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.08it/s]\n     0.783     0.544     0.479\n\n     epoch    memory      loss\n   394/500     3.03G     4.949: 100%|█████████████| 4/4 [00:02<00:00,  1.51it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.92it/s]\n     0.798     0.553     0.491\n\n     epoch    memory      loss\n   395/500     3.02G     5.131: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.744     0.587     0.495\n\n     epoch    memory      loss\n   396/500     2.66G     5.088: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.74it/s]\n     0.725     0.609      0.49\n\n     epoch    memory      loss\n   397/500     2.71G     4.818: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.82it/s]\n     0.792     0.587     0.502\n\n     epoch    memory      loss\n   398/500     3.12G     4.925: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n     0.822     0.586     0.494\n\n     epoch    memory      loss\n   399/500     3.13G     4.794: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.08it/s]\n     0.823     0.583     0.497\n\n     epoch    memory      loss\n   400/500     3.21G     4.799: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.793     0.612     0.499\n\n     epoch    memory      loss\n   401/500     3.05G     4.896: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.99it/s]\n      0.79     0.611     0.498\n\n     epoch    memory      loss\n   402/500     3.19G     4.859: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.86it/s]\n      0.79     0.608     0.503\n\n     epoch    memory      loss\n   403/500     3.38G     4.957: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.85it/s]\n      0.78     0.617     0.505\n\n     epoch    memory      loss\n   404/500     3.17G     4.768: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n      0.81     0.613     0.507\n\n     epoch    memory      loss\n   405/500     3.13G     4.786: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.821     0.603     0.513\n\n     epoch    memory      loss\n   406/500     3.33G     4.871: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.814     0.595      0.51\n\n     epoch    memory      loss\n   407/500     3.06G     4.963: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.65it/s]\n     0.826     0.579     0.504\n\n     epoch    memory      loss\n   408/500     3.02G     5.077: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.12it/s]\n     0.817     0.583     0.504\n\n     epoch    memory      loss\n   409/500     2.71G     4.789: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.00it/s]\n     0.835      0.59      0.51\n\n     epoch    memory      loss\n   410/500     3.35G     4.888: 100%|█████████████| 4/4 [00:02<00:00,  1.50it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.95it/s]\n     0.862     0.605     0.513\n\n     epoch    memory      loss\n   411/500     3.27G     4.972: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.796     0.607     0.521\n\n     epoch    memory      loss\n   412/500     3.52G      4.79: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.743     0.633     0.517\n\n     epoch    memory      loss\n   413/500     3.75G     4.825: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.70it/s]\n      0.81     0.613     0.512\n\n     epoch    memory      loss\n   414/500     3.09G     4.769: 100%|█████████████| 4/4 [00:02<00:00,  1.35it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.90it/s]\n     0.833     0.591     0.516\n\n     epoch    memory      loss\n   415/500      3.2G     4.861: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.792     0.632     0.522\n\n     epoch    memory      loss\n   416/500     3.11G     4.763: 100%|█████████████| 4/4 [00:02<00:00,  1.51it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.94it/s]\n     0.818     0.626     0.519\n\n     epoch    memory      loss\n   417/500     3.02G     4.768: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.34it/s]\n     0.778      0.62     0.522\n\n     epoch    memory      loss\n   418/500     3.01G     4.842: 100%|█████████████| 4/4 [00:02<00:00,  1.53it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.79it/s]\n     0.767     0.619     0.515\n\n     epoch    memory      loss\n   419/500     3.08G     4.667: 100%|█████████████| 4/4 [00:02<00:00,  1.47it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.99it/s]\n     0.801     0.582     0.517\n\n     epoch    memory      loss\n   420/500     3.07G     4.774: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.834     0.608     0.523\n\n     epoch    memory      loss\n   421/500     3.31G     4.812: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.848     0.612     0.522\n\n     epoch    memory      loss\n   422/500     3.41G     4.738: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.848     0.597     0.521\n\n     epoch    memory      loss\n   423/500     3.31G     4.796: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n     0.826     0.617     0.526\n\n     epoch    memory      loss\n   424/500     3.07G     4.836: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.845     0.607     0.533\n\n     epoch    memory      loss\n   425/500     3.11G     4.778: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.68it/s]\n     0.809     0.651      0.54\n\n     epoch    memory      loss\n   426/500      3.1G     4.754: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.76it/s]\n     0.808     0.647     0.539\n\n     epoch    memory      loss\n   427/500     3.18G     4.736: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.12it/s]\n     0.835     0.614     0.541\n\n     epoch    memory      loss\n   428/500      3.1G     4.728: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.78it/s]\n     0.811      0.62     0.535\n\n     epoch    memory      loss\n   429/500     3.14G     4.678: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.841     0.619     0.532\n\n     epoch    memory      loss\n   430/500     3.04G     4.823: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.819     0.626     0.534\n\n     epoch    memory      loss\n   431/500     3.23G     4.689: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.82it/s]\n      0.82     0.622     0.538\n\n     epoch    memory      loss\n   432/500      3.2G     4.524: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.834     0.605     0.534\n\n     epoch    memory      loss\n   433/500     3.09G     4.721: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.98it/s]\n      0.77     0.644     0.534\n\n     epoch    memory      loss\n   434/500     3.09G     4.717: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.06it/s]\n     0.854     0.609     0.532\n\n     epoch    memory      loss\n   435/500     3.21G     4.729: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.832     0.635      0.54\n\n     epoch    memory      loss\n   436/500     3.05G     4.679: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.92it/s]\n     0.801     0.628     0.535\n\n     epoch    memory      loss\n   437/500     3.16G     4.681: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.812     0.623     0.542\n\n     epoch    memory      loss\n   438/500     3.22G      4.73: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.69it/s]\n     0.811     0.638     0.542\n\n     epoch    memory      loss\n   439/500      3.2G     4.701: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.84it/s]\n     0.776      0.65      0.54\n\n     epoch    memory      loss\n   440/500     3.16G     4.551: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.44it/s]\n     0.819      0.62     0.543\n\n     epoch    memory      loss\n   441/500     3.16G     4.638: 100%|█████████████| 4/4 [00:03<00:00,  1.33it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.88it/s]\n     0.799     0.629     0.544\n\n     epoch    memory      loss\n   442/500     2.69G     4.558: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.56it/s]\n     0.813     0.637     0.543\n\n     epoch    memory      loss\n   443/500     2.69G     4.982: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.90it/s]\n      0.73     0.692     0.538\n\n     epoch    memory      loss\n   444/500      3.1G     4.598: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.59it/s]\n     0.736     0.695     0.547\n\n     epoch    memory      loss\n   445/500     3.28G     4.621: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.44it/s]\n     0.751     0.675     0.547\n\n     epoch    memory      loss\n   446/500      3.2G     4.707: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.63it/s]\n     0.778     0.667     0.544\n\n     epoch    memory      loss\n   447/500     3.05G     4.551: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.86it/s]\n     0.799     0.651     0.545\n\n     epoch    memory      loss\n   448/500     3.19G     4.506: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.53it/s]\n     0.798     0.643     0.551\n\n     epoch    memory      loss\n   449/500     2.67G     4.527: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.93it/s]\n     0.749      0.67     0.554\n\n     epoch    memory      loss\n   450/500      3.3G     4.556: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.65it/s]\n     0.739     0.694     0.559\n\n     epoch    memory      loss\n   451/500     3.01G     4.509: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.803     0.648     0.558\n\n     epoch    memory      loss\n   452/500     2.67G     4.599: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.78it/s]\n     0.845      0.64     0.557\n\n     epoch    memory      loss\n   453/500      2.7G     4.625: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.68it/s]\n     0.873     0.631     0.561\n\n     epoch    memory      loss\n   454/500     3.18G     4.451: 100%|█████████████| 4/4 [00:03<00:00,  1.29it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.68it/s]\n     0.814      0.67      0.56\n\n     epoch    memory      loss\n   455/500     3.18G     4.555: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.99it/s]\n     0.807     0.669      0.56\n\n     epoch    memory      loss\n   456/500      3.3G      4.55: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.85it/s]\n     0.795     0.679     0.554\n\n     epoch    memory      loss\n   457/500     3.21G     4.554: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.00it/s]\n     0.796     0.664     0.553\n\n     epoch    memory      loss\n   458/500     3.12G     4.646: 100%|█████████████| 4/4 [00:02<00:00,  1.49it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.06it/s]\n     0.806     0.673     0.565\n\n     epoch    memory      loss\n   459/500     3.21G     4.645: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.72it/s]\n     0.825     0.659     0.567\n\n     epoch    memory      loss\n   460/500     3.27G     4.486: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.79it/s]\n     0.811     0.669     0.567\n\n     epoch    memory      loss\n   461/500     2.71G     4.629: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.75it/s]\n     0.806     0.662     0.565\n\n     epoch    memory      loss\n   462/500     3.32G     4.568: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.79it/s]\n     0.766     0.693     0.566\n\n     epoch    memory      loss\n   463/500     3.29G     4.633: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.71it/s]\n     0.785      0.68     0.565\n\n     epoch    memory      loss\n   464/500     3.18G      4.53: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.82it/s]\n     0.791     0.671     0.568\n\n     epoch    memory      loss\n   465/500     3.26G     4.665: 100%|█████████████| 4/4 [00:02<00:00,  1.37it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.83it/s]\n     0.779     0.696     0.571\n\n     epoch    memory      loss\n   466/500     3.45G     4.468: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.77it/s]\n     0.763     0.686     0.572\n\n     epoch    memory      loss\n   467/500      3.3G     4.474: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.03it/s]\n     0.781     0.678     0.571\n\n     epoch    memory      loss\n   468/500     3.25G      4.49: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.75it/s]\n     0.789     0.676     0.567\n\n     epoch    memory      loss\n   469/500     3.07G      4.44: 100%|█████████████| 4/4 [00:02<00:00,  1.42it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.74it/s]\n     0.785     0.686     0.571\n\n     epoch    memory      loss\n   470/500     3.27G     4.634: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.71it/s]\n     0.788      0.69     0.573\n\n     epoch    memory      loss\n   471/500     3.06G     4.505: 100%|█████████████| 4/4 [00:02<00:00,  1.48it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.78it/s]\n     0.789     0.689     0.574\n\n     epoch    memory      loss\n   472/500     3.14G     4.494: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.54it/s]\n     0.771     0.693     0.573\n\n     epoch    memory      loss\n   473/500     3.54G     4.548: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.24it/s]\n     0.779     0.697     0.571\n\n     epoch    memory      loss\n   474/500     3.05G     4.454: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.836     0.649     0.575\n\n     epoch    memory      loss\n   475/500      3.2G     4.442: 100%|█████████████| 4/4 [00:02<00:00,  1.41it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.67it/s]\n     0.873     0.633     0.582\n\n     epoch    memory      loss\n   476/500     3.28G     4.422: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.78it/s]\n     0.865     0.632     0.577\n\n     epoch    memory      loss\n   477/500     3.12G     4.481: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.54it/s]\n     0.868     0.634     0.573\n\n     epoch    memory      loss\n   478/500     3.36G     4.479: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.80it/s]\n     0.879     0.635     0.572\n\n     epoch    memory      loss\n   479/500     3.06G     4.466: 100%|█████████████| 4/4 [00:02<00:00,  1.36it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.45it/s]\n     0.874     0.641     0.573\n\n     epoch    memory      loss\n   480/500     3.34G     4.584: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.73it/s]\n     0.878     0.644     0.572\n\n     epoch    memory      loss\n   481/500     3.05G     4.493: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.70it/s]\n     0.867     0.646     0.576\n\n     epoch    memory      loss\n   482/500     3.11G     4.477: 100%|█████████████| 4/4 [00:02<00:00,  1.40it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.81it/s]\n     0.851     0.653     0.574\n\n     epoch    memory      loss\n   483/500     3.09G     4.432: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.82it/s]\n     0.845      0.65     0.577\n\n     epoch    memory      loss\n   484/500     3.08G     4.432: 100%|█████████████| 4/4 [00:02<00:00,  1.43it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.95it/s]\n     0.835     0.662     0.578\n\n     epoch    memory      loss\n   485/500     3.03G     4.453: 100%|█████████████| 4/4 [00:02<00:00,  1.38it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.76it/s]\n     0.773     0.703     0.581\n\n     epoch    memory      loss\n   486/500     3.12G     4.566: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.18it/s]\n     0.801     0.686     0.579\n\n     epoch    memory      loss\n   487/500     3.28G     4.563: 100%|█████████████| 4/4 [00:02<00:00,  1.45it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.87it/s]\n     0.818     0.683     0.578\n\n     epoch    memory      loss\n   488/500     3.21G     4.595: 100%|█████████████| 4/4 [00:02<00:00,  1.46it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.02it/s]\n     0.835     0.677     0.583\n\n     epoch    memory      loss\n   489/500     3.16G     4.561: 100%|█████████████| 4/4 [00:02<00:00,  1.44it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.93it/s]\n     0.846     0.677     0.582\n\n     epoch    memory      loss\n   490/500     2.71G     4.293: 100%|█████████████| 4/4 [00:02<00:00,  1.39it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.74it/s]\n     0.837     0.681     0.581\n\n     epoch    memory      loss\n   491/500     2.67G     4.548: 100%|█████████████| 4/4 [00:02<00:00,  1.71it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.84it/s]\n      0.84     0.686     0.581\n\n     epoch    memory      loss\n   492/500     3.08G     4.385: 100%|█████████████| 4/4 [00:02<00:00,  1.68it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.91it/s]\n     0.814     0.693     0.582\n\n     epoch    memory      loss\n   493/500     3.16G     4.409: 100%|█████████████| 4/4 [00:02<00:00,  1.68it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  8.91it/s]\n     0.807     0.693     0.575\n\n     epoch    memory      loss\n   494/500     3.18G     4.398: 100%|█████████████| 4/4 [00:02<00:00,  1.78it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.93it/s]\n     0.813     0.683     0.567\n\n     epoch    memory      loss\n   495/500      2.7G     4.259: 100%|█████████████| 4/4 [00:02<00:00,  1.64it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.97it/s]\n      0.81     0.683     0.564\n\n     epoch    memory      loss\n   496/500     2.68G     4.244: 100%|█████████████| 4/4 [00:02<00:00,  1.77it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.76it/s]\n     0.813     0.685     0.561\n\n     epoch    memory      loss\n   497/500     3.16G      4.46: 100%|█████████████| 4/4 [00:02<00:00,  1.75it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.73it/s]\n     0.808     0.688     0.563\n\n     epoch    memory      loss\n   498/500     2.67G      4.03: 100%|█████████████| 4/4 [00:02<00:00,  1.70it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.96it/s]\n     0.815     0.682      0.56\n\n     epoch    memory      loss\n   499/500     3.16G     4.238: 100%|█████████████| 4/4 [00:02<00:00,  1.74it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00, 10.11it/s]\n     0.816     0.679     0.561\n\n     epoch    memory      loss\n   500/500      2.7G     4.279: 100%|█████████████| 4/4 [00:02<00:00,  1.75it/s]\n precision    recall       mAP: 100%|███████████| 15/15 [00:01<00:00,  9.84it/s]\n     0.811     0.682     0.566\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":" ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"!python3 main.py --test","metadata":{"id":"X6j7elt75oL_","execution":{"iopub.status.busy":"2025-05-02T04:35:30.960780Z","iopub.execute_input":"2025-05-02T04:35:30.961007Z","iopub.status.idle":"2025-05-02T04:35:34.819136Z","shell.execute_reply.started":"2025-05-02T04:35:30.960985Z","shell.execute_reply":"2025-05-02T04:35:34.818223Z"}}},{"cell_type":"code","source":"!python3 main.py --test","metadata":{"id":"WGAabdTu5oOu","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T13:51:38.068903Z","iopub.execute_input":"2025-05-06T13:51:38.069221Z","iopub.status.idle":"2025-05-06T13:51:45.791231Z","shell.execute_reply.started":"2025-05-06T13:51:38.069198Z","shell.execute_reply":"2025-05-06T13:51:45.790586Z"}},"outputs":[{"name":"stdout","text":" precision    recall       mAP: 100%|███████████| 15/15 [00:02<00:00,  6.70it/s]\n     0.835     0.677     0.583\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CUDA_LAUNCH_BLOCKING=1 python train.py --batch-size 16\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T13:36:50.268609Z","iopub.execute_input":"2025-05-06T13:36:50.268895Z","iopub.status.idle":"2025-05-06T13:36:50.272667Z","shell.execute_reply.started":"2025-05-06T13:36:50.268868Z","shell.execute_reply":"2025-05-06T13:36:50.271982Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}